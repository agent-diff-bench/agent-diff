{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOPnafqbGV-Y"
      },
      "source": [
        "# Import Libraries and Files for Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 4447,
          "status": "ok",
          "timestamp": 1768560999430,
          "user": {
            "displayName": "Hubert Pyskło",
            "userId": "16424235253540376255"
          },
          "user_tz": -330
        },
        "id": "W76Uv3xbJofP",
        "outputId": "0949c6c7-b7fe-4264-fbfb-b7a9c45a948a"
      },
      "outputs": [],
      "source": [
        "%pip install -q langchain langchain-openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "executionInfo": {
          "elapsed": 4646,
          "status": "ok",
          "timestamp": 1768560960955,
          "user": {
            "displayName": "Hubert Pyskło",
            "userId": "16424235253540376255"
          },
          "user_tz": -330
        },
        "id": "tnDYZEjhFnZK",
        "outputId": "e485d3f4-54f3-4e59-834d-c887bd96f2ce"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\nCurrent format of evaluation results (each item in the results array):\\n{\\n    # Test identification\\n    \"test_id\": \"e4494bce-7101-5ec5-b757-f90f57c53690\",  # UUID, constant across runs\\n    \"test_name\": \"Update channel topic\",                 # Human-readable name\\n    \"test_suite_name\": \"Slack Bench v2\",                 # Test suite name\\n    \"service\": \"slack\",                                  # Service: slack, box, calendar, linear\\n    \\n    # Run identification\\n    \"runId\": \"5003bf1b-72b8-4f6d-8708-430d13d01b11\",    # Unique run UUID\\n    \"run_index\": 0,                                      # Which run (0, 1, 2...) for runs_per_test > 1\\n    \"model\": \"moonshotai/kimi-k2-0905\",                  # Model identifier\\n    \"timestamp\": \"2026-02-02T16:22:44.060562\",          # ISO timestamp\\n    \\n    # Task\\n    \"prompt\": \"Change the #general channel topic to...\", # Task prompt\\n    \"include_api_docs\": false,                           # Whether API docs were in system prompt\\n    \\n    # Results\\n    \"status\": \"passed\",                                  # \"passed\", \"failed\", \"timeout\", \"error\"\\n    \"passed\": true,                                      # Boolean pass/fail\\n    \"score\": 100.0,                                      # Score 0-100\\n    \"time\": 15.68,                                       # Execution time in seconds\\n    \"failures\": [],                                      # List of failure messages (if any)\\n    \\n    # Execution trace\\n    \"trace\": [...]                                       # Full execution trace (tool calls, responses, errors)\\n}\\n'"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "import json, os, glob\n",
        "import random\n",
        "import time\n",
        "\n",
        "# from google.colab import drive\n",
        "# from google.colab import userdata\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "from collections import defaultdict\n",
        "from datetime import datetime\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "\n",
        "from pydantic import BaseModel, Field\n",
        "from typing import Literal, List, Dict, Any, Optional\n",
        "from enum import Enum\n",
        "from pprint import pprint\n",
        "\n",
        "from langchain.agents import create_agent\n",
        "from langchain.agents.structured_output import ToolStrategy\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.messages import BaseMessage\n",
        "\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "from utils.create_tests_metadata import get_or_create_tests_metadata\n",
        "from utils.clean_server_errors import get_or_create_cleaned_results\n",
        "\n",
        "# ============================================\n",
        "# Robust OpenRouter Wrapper with Retry Logic\n",
        "# ============================================\n",
        "class RobustChatOpenAI(ChatOpenAI):\n",
        "    \"\"\"\n",
        "    A wrapper around ChatOpenAI that adds robust retry logic for OpenRouter API calls.\n",
        "    \n",
        "    Handles transient failures (502, 503, 429, etc.) with exponential backoff.\n",
        "    Maintains full compatibility with LangChain's ChatOpenAI interface.\n",
        "    \"\"\"\n",
        "    \n",
        "    max_retries: int | None = 3\n",
        "    base_delay: float = 2.0\n",
        "    retryable_status_codes: tuple = (400, 429, 500, 502, 503, 504)\n",
        "    \n",
        "    def _should_retry(self, exception: Exception) -> bool:\n",
        "        \"\"\"Determine if the exception is retryable.\"\"\"\n",
        "        import httpx\n",
        "        from openai import APIStatusError, APIConnectionError, APITimeoutError\n",
        "        \n",
        "        # OpenAI SDK exceptions (used by langchain_openai)\n",
        "        if isinstance(exception, APIConnectionError):\n",
        "            return True\n",
        "        if isinstance(exception, APITimeoutError):\n",
        "            return True\n",
        "        if isinstance(exception, APIStatusError):\n",
        "            return exception.status_code in self.retryable_status_codes\n",
        "        \n",
        "        # httpx exceptions (fallback)\n",
        "        if isinstance(exception, (httpx.ConnectError, httpx.ReadError, httpx.RemoteProtocolError)):\n",
        "            return True\n",
        "        if isinstance(exception, httpx.HTTPStatusError):\n",
        "            return exception.response.status_code in self.retryable_status_codes\n",
        "            \n",
        "        return False\n",
        "    \n",
        "    def _retry_with_backoff(self, func, *args, **kwargs):\n",
        "        \"\"\"Execute function with retry logic and exponential backoff.\"\"\"\n",
        "        last_error = None\n",
        "        n = self.max_retries if self.max_retries is not None else 3\n",
        "\n",
        "        for attempt in range(n):\n",
        "            try:\n",
        "                return func(*args, **kwargs)\n",
        "            except Exception as e:\n",
        "                last_error = e\n",
        "                \n",
        "                if self._should_retry(e) and attempt < n - 1:\n",
        "                    delay = self.base_delay * (2 ** attempt) + random.uniform(0, 1)\n",
        "                    print(f\"[RETRY] OpenRouter request failed (attempt {attempt + 1}/{n}): {e}. Retrying in {delay:.1f}s...\")\n",
        "                    time.sleep(delay)\n",
        "                    continue\n",
        "                raise\n",
        "        \n",
        "        raise last_error\n",
        "    \n",
        "    def invoke(self, input, config=None, **kwargs):\n",
        "        \"\"\"Override invoke with retry logic.\"\"\"\n",
        "        return self._retry_with_backoff(super().invoke, input, config, **kwargs)\n",
        "    \n",
        "    def generate(self, messages: List[List[BaseMessage]], stop: Optional[List[str]] = None, **kwargs):\n",
        "        \"\"\"Override generate with retry logic.\"\"\"\n",
        "        return self._retry_with_backoff(super().generate, messages, stop, **kwargs)\n",
        "    \n",
        "    def _generate(self, messages: List[BaseMessage], stop: Optional[List[str]] = None, **kwargs):\n",
        "        \"\"\"Override _generate with retry logic.\"\"\"\n",
        "        return self._retry_with_backoff(super()._generate, messages, stop, **kwargs)\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Current format of evaluation results (each item in the results array):\n",
        "{\n",
        "    # Test identification\n",
        "    \"test_id\": \"e4494bce-7101-5ec5-b757-f90f57c53690\",  # UUID, constant across runs\n",
        "    \"test_name\": \"Update channel topic\",                 # Human-readable name\n",
        "    \"test_suite_name\": \"Slack Bench v2\",                 # Test suite name\n",
        "    \"service\": \"slack\",                                  # Service: slack, box, calendar, linear\n",
        "    \n",
        "    # Run identification\n",
        "    \"runId\": \"5003bf1b-72b8-4f6d-8708-430d13d01b11\",    # Unique run UUID\n",
        "    \"run_index\": 0,                                      # Which run (0, 1, 2...) for runs_per_test > 1\n",
        "    \"model\": \"moonshotai/kimi-k2-0905\",                  # Model identifier\n",
        "    \"timestamp\": \"2026-02-02T16:22:44.060562\",          # ISO timestamp\n",
        "    \n",
        "    # Task\n",
        "    \"prompt\": \"Change the #general channel topic to...\", # Task prompt\n",
        "    \"include_api_docs\": false,                           # Whether API docs were in system prompt\n",
        "    \n",
        "    # Results\n",
        "    \"status\": \"passed\",                                  # \"passed\", \"failed\", \"timeout\", \"error\"\n",
        "    \"passed\": true,                                      # Boolean pass/fail\n",
        "    \"score\": 100.0,                                      # Score 0-100\n",
        "    \"time\": 15.68,                                       # Execution time in seconds\n",
        "    \"failures\": [],                                      # List of failure messages (if any)\n",
        "    \n",
        "    # Execution trace\n",
        "    \"trace\": [...]                                       # Full execution trace (tool calls, responses, errors)\n",
        "}\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Import all test suites and runs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading existing cleaned results from: cleaned_preprocessed_merged_results_20260207_165600.json\n",
            "Loaded 13516 cleaned runs\n",
            "Working with 13516 cleaned runs\n",
            "Loaded existing tests metadata with 224 tests\n",
            "Loaded metadata for 224 tests\n"
          ]
        }
      ],
      "source": [
        "# Import merged results, clean server errors, and load tests metadata\n",
        "\n",
        "MERGED_RESULTS_FILE = \"preprocessed_merged_results.json\"\n",
        "\n",
        "# Get or create cleaned results (removes runs with server errors)\n",
        "runs, cleaned_filepath = get_or_create_cleaned_results(MERGED_RESULTS_FILE)\n",
        "print(f\"Working with {len(runs)} cleaned runs\")\n",
        "\n",
        "# Get or create tests metadata (maps runtime_test_id -> test info)\n",
        "tests_metadata = get_or_create_tests_metadata(\n",
        "    merged_results_path=MERGED_RESULTS_FILE,\n",
        "    test_suites_folder=\"test_suites\",\n",
        "    output_folder=\"tests_metadata\"\n",
        ")\n",
        "\n",
        "print(f\"Loaded metadata for {len(tests_metadata)} tests\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original runs: 13516\n",
            "Skipped (all_docs): 6033\n",
            "Total (test_id, model) groups: 2004\n",
            "Missing 'none' doc runs: 16\n",
            "Missing 'relevant' doc runs: 29\n",
            "Sampled runs: 3963\n",
            "\n",
            "============================================================\n",
            "VERIFICATION: Counts per model per doc level\n",
            "============================================================\n",
            "  anthropic/claude-haiku-4.5: none=222, relevant=222 [OK]\n",
            "  deepseek/deepseek-v3.2: none=220, relevant=220 [OK]\n",
            "  google/gemini-3-flash-preview: none=222, relevant=222 [OK]\n",
            "  meta-llama/llama-4-scout: none=217, relevant=208 [IMBALANCED]\n",
            "  mistralai/devstral-2512: none=222, relevant=222 [OK]\n",
            "  moonshotai/kimi-k2-0905: none=221, relevant=218 [IMBALANCED]\n",
            "  openai/gpt-oss-120b: none=220, relevant=223 [IMBALANCED]\n",
            "  qwen/qwen3-vl-235b-a22b-instruct: none=222, relevant=221 [IMBALANCED]\n",
            "  x-ai/grok-4.1-fast: none=222, relevant=219 [IMBALANCED]\n",
            "\n",
            "All models balanced: False\n"
          ]
        }
      ],
      "source": [
        "def sample_runs_by_model_test_stratified(runs, seed=42):\n",
        "    \"\"\"\n",
        "    Sample 2 runs per (test_id, model) group from the full dataset:\n",
        "    - 1 run with no documentation (include_api_docs=False)\n",
        "    - 1 run with relevant documentation only (include_api_docs=True, include_all_api_docs=False)\n",
        "    \n",
        "    Excludes runs with all documentation (include_all_api_docs=True).\n",
        "    \n",
        "    Args:\n",
        "        runs: List of run dictionaries\n",
        "        seed: Random seed for reproducibility\n",
        "    \n",
        "    Returns:\n",
        "        Tuple of (sampled_runs, stats_dict)\n",
        "    \"\"\"\n",
        "    random.seed(seed)\n",
        "    \n",
        "    # Group runs by (test_id, model, doc_level)\n",
        "    groups = defaultdict(lambda: {\"none\": [], \"relevant\": []})\n",
        "    skipped_all_docs = 0\n",
        "    \n",
        "    for run in runs:\n",
        "        # Skip runs with all documentation\n",
        "        if run.get(\"include_all_api_docs\"):\n",
        "            skipped_all_docs += 1\n",
        "            continue\n",
        "        \n",
        "        key = (run[\"test_id\"], run[\"model\"])\n",
        "        if run.get(\"include_api_docs\"):\n",
        "            groups[key][\"relevant\"].append(run)\n",
        "        else:\n",
        "            groups[key][\"none\"].append(run)\n",
        "    \n",
        "    # Sample 1 from each doc level per (test_id, model)\n",
        "    sampled_runs = []\n",
        "    missing = {\"none\": [], \"relevant\": []}  # Track which (test_id, model) are missing\n",
        "    \n",
        "    for key, doc_groups in groups.items():\n",
        "        for doc_level in [\"none\", \"relevant\"]:\n",
        "            if doc_groups[doc_level]:\n",
        "                selected_run = random.choice(doc_groups[doc_level])\n",
        "                sampled_runs.append(selected_run)\n",
        "            else:\n",
        "                missing[doc_level].append(key)\n",
        "    \n",
        "    stats = {\n",
        "        \"skipped_all_docs\": skipped_all_docs,\n",
        "        \"total_groups\": len(groups),\n",
        "        \"missing_none\": len(missing[\"none\"]),\n",
        "        \"missing_relevant\": len(missing[\"relevant\"]),\n",
        "        \"sampled_runs\": len(sampled_runs)\n",
        "    }\n",
        "    \n",
        "    return sampled_runs, stats\n",
        "\n",
        "\n",
        "# Apply sampling\n",
        "sampled_runs, stats = sample_runs_by_model_test_stratified(runs)\n",
        "print(f\"Original runs: {len(runs)}\")\n",
        "print(f\"Skipped (all_docs): {stats['skipped_all_docs']}\")\n",
        "print(f\"Total (test_id, model) groups: {stats['total_groups']}\")\n",
        "print(f\"Missing 'none' doc runs: {stats['missing_none']}\")\n",
        "print(f\"Missing 'relevant' doc runs: {stats['missing_relevant']}\")\n",
        "print(f\"Sampled runs: {stats['sampled_runs']}\")\n",
        "\n",
        "# Verification: counts per model per doc level\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"VERIFICATION: Counts per model per doc level\")\n",
        "print(\"=\"*60)\n",
        "doc_by_model = defaultdict(lambda: {\"none\": 0, \"relevant\": 0})\n",
        "for run in sampled_runs:\n",
        "    model = run[\"model\"]\n",
        "    if run.get(\"include_api_docs\"):\n",
        "        doc_by_model[model][\"relevant\"] += 1\n",
        "    else:\n",
        "        doc_by_model[model][\"none\"] += 1\n",
        "\n",
        "all_balanced = True\n",
        "for model, counts in sorted(doc_by_model.items()):\n",
        "    balanced = \"OK\" if counts[\"none\"] == counts[\"relevant\"] else \"IMBALANCED\"\n",
        "    if balanced != \"OK\":\n",
        "        all_balanced = False\n",
        "    print(f\"  {model}: none={counts['none']}, relevant={counts['relevant']} [{balanced}]\")\n",
        "\n",
        "print(f\"\\nAll models balanced: {all_balanced}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "18\n"
          ]
        }
      ],
      "source": [
        "print(len([run for run in sampled_runs if run[\"test_id\"] == \"f1e306ca-d89a-5d70-bb57-03437eec4ea8\"]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Format all runs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "def format_single_run(run):\n",
        "    \"\"\"\n",
        "    Format a single run into a structured dict for qualitative analysis.\n",
        "    \n",
        "    Args:\n",
        "        run: Raw run dict containing test_suite_name, status, prompt, trace, etc.\n",
        "        \n",
        "    Returns:\n",
        "        dict with structure:\n",
        "        {\n",
        "            \"run_id\": str,\n",
        "            \"runtime_test_id\": str,  # For mapping to tests_metadata\n",
        "            \"score\": int,            # base_score (0-100), NOT weighted score\n",
        "            \"iterations\": int,\n",
        "            \"include_api_docs\": bool,\n",
        "            \"include_all_api_docs\": bool,\n",
        "            \"formatted_trace\": str  # Human-readable trace narrative\n",
        "        }\n",
        "        \n",
        "        Or None if run has status \"error\".\n",
        "    \"\"\" \n",
        "    run_id = run.get(\"run_id\")  # Changed from \"runId\" to \"run_id\"\n",
        "    runtime_test_id = run.get(\"test_id\")\n",
        "    status = run[\"status\"]\n",
        "    \n",
        "    if status == \"error\":\n",
        "        return None\n",
        "    \n",
        "    prompt = run[\"prompt\"]\n",
        "    \n",
        "    formatted_trace = \"\"\n",
        "    \n",
        "    trace_intro = f'The agent was asked to complete this task: \"{prompt}\"\\n\\n'\n",
        "    if status == \"passed\":\n",
        "        status_update = \"The agent was able to complete the task SUCCESSFULLY.\"\n",
        "    elif status == \"failed\":\n",
        "        status_update = \"The agent FAILED to complete the task.\"\n",
        "    else: # status == \"terminated\" \n",
        "        status_update = \"The agent FAILED to complete the task. The agent was not able to complete it within the designated time interval, which led to an automatic failure.\"\n",
        "    \n",
        "    formatted_trace += trace_intro + status_update + '\\n'\n",
        "    \n",
        "    trace = run[\"trace\"]\n",
        "    for step in trace[\"steps\"]:\n",
        "        \n",
        "        # Check if step has any meaningful content\n",
        "        has_thinking = 'thinking' in step\n",
        "        has_action = 'action' in step\n",
        "        has_stdout = 'observation' in step and step['observation'].get('stdout')\n",
        "        has_stderr = ('observation' in step and \n",
        "                      step['observation'].get('stderr') and \n",
        "                      not step['observation'].get('stderr', '').strip().startswith('% Total'))\n",
        "        \n",
        "        if not has_thinking and not has_action and not has_stdout and not has_stderr:\n",
        "            formatted_trace += f\"Nothing has happened during iteration # {step['iteration']}.\\n\\n\"\n",
        "        \n",
        "        else:\n",
        "            iteration_num = step['iteration']\n",
        "            intro = f\"This is what happened during iteration #{iteration_num}:\\n\"\n",
        "            thinking = f\"\\t- This was the agent's reasoning during iteration #{iteration_num}: {step['thinking']}\\n\" if 'thinking' in step else \"\"\n",
        "            action = f\"\\t- This was the agent's action(s) during iteration #{iteration_num}: {step['action']}\\n\" if 'action' in step else \"\"\n",
        "            \n",
        "            if \"result\" not in step or len(step[\"result\"]) == 0:\n",
        "                result = \"\"\n",
        "            else:\n",
        "                result = f\"\\t- This resulted in this stdout output: {step['observation']['stdout']}\\n\"\n",
        "                # Include stderr if present and meaningful (not curl progress output)\n",
        "                stderr = step['observation'].get('stderr', '')\n",
        "                if stderr and not stderr.strip().startswith('% Total'):\n",
        "                    result += f\"\\t- This also produced stderr output: {stderr}\\n\"\n",
        "                \n",
        "            formatted_trace += intro + thinking + action + result + '\\n'\n",
        "            \n",
        "    \n",
        "    final_iteration = trace[\"final\"]\n",
        "    \n",
        "    if final_iteration:\n",
        "        formatted_trace += f\"Iteration #{final_iteration['iteration']} was the final iteration.\"\n",
        "        \n",
        "        if ('iteration' not in final_iteration and \n",
        "            'summary' not in final_iteration):\n",
        "            formatted_trace += \"Nothing happened during the final iteration.\\n\\n\"\n",
        "        else:\n",
        "            formatted_trace += \"This is what happened during the final iteration:\\n\"\n",
        "            final_thinking = f\"\\t- The agent produced such reasoning: {final_iteration['thinking']}\\n\" if 'thinking' in final_iteration else \"\"\n",
        "            summary = f\"\\t- The reasoning was followed by this summary: {final_iteration['summary']}\\n\\n\" if 'summary' in final_iteration else \"\"\n",
        "            \n",
        "            formatted_trace += final_thinking + summary\n",
        "    \n",
        "    include_all_api_docs = run.get(\"include_all_api_docs\", False)\n",
        "    \n",
        "    formatted_run = {\n",
        "        \"run_id\": run_id,\n",
        "        \"runtime_test_id\": runtime_test_id,\n",
        "        \"score\": run[\"base_score\"],  # Changed from \"score\" - use base_score (0-100)\n",
        "        \"iterations\": trace[\"iterations\"],\n",
        "        \"include_api_docs\": run[\"include_api_docs\"],\n",
        "        \"include_all_api_docs\": include_all_api_docs,\n",
        "        \"formatted_trace\": formatted_trace\n",
        "    }\n",
        "    \n",
        "    return formatted_run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "executionInfo": {
          "elapsed": 52,
          "status": "ok",
          "timestamp": 1768563670214,
          "user": {
            "displayName": "Hubert Pyskło",
            "userId": "16424235253540376255"
          },
          "user_tz": -330
        },
        "id": "HbitvMNAWFTo"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved 3963 formatted runs to: /Users/azh/agent-diff/local_analysis/formatted_runs/all_runs_formatted_20260208_163423.json\n"
          ]
        }
      ],
      "source": [
        "# Format all runs and store it in a separate file\n",
        "formatted_runs = [format_single_run(run) for run in sampled_runs]\n",
        "formatted_runs = [r for r in formatted_runs if r is not None]\n",
        "\n",
        "# Create folder if needed\n",
        "output_folder = os.path.join(os.getcwd(), \"formatted_runs\")\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# Save with timestamp\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "filepath = os.path.join(output_folder, f\"all_runs_formatted_{timestamp}.json\")\n",
        "\n",
        "with open(filepath, 'w') as f:\n",
        "    json.dump(formatted_runs, f, indent=2)\n",
        "\n",
        "print(f\"Saved {len(formatted_runs)} formatted runs to: {filepath}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "18\n"
          ]
        }
      ],
      "source": [
        "print(len([run for run in formatted_runs if run[\"runtime_test_id\"] == \"f1e306ca-d89a-5d70-bb57-03437eec4ea8\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "RunAnalysisSchema = {\n",
        "    \"type\": \"object\",\n",
        "    \"additionalProperties\": False,\n",
        "    \"properties\": {\n",
        "        \"tool_use_errors\": {\n",
        "            \"type\": \"object\",\n",
        "            \"description\": \"Errors related to how the agent interacts with tools and APIs.\",\n",
        "            \"additionalProperties\": False,\n",
        "            \"properties\": {\n",
        "                \"endpoint_selection\": {\n",
        "                    \"type\": \"object\",\n",
        "                    \"additionalProperties\": False,\n",
        "                    \"properties\": {\n",
        "                        \"present\": {\"type\": \"boolean\", \"description\": \"True if there are any incorrect or irrelevant endpoint choices.\"},\n",
        "                        \"explanation\": {\"type\": \"string\", \"description\": \"Brief summary of the issue (or why none were found).\"},\n",
        "                        \"example\": {\"type\": \"string\", \"description\": \"One concrete example from the trace (or 'N/A' if none).\"}\n",
        "                    },\n",
        "                    \"required\": [\"present\", \"explanation\", \"example\"]\n",
        "                },\n",
        "                \"parameter_misuse\": {\n",
        "                    \"type\": \"object\",\n",
        "                    \"additionalProperties\": False,\n",
        "                    \"properties\": {\n",
        "                        \"present\": {\"type\": \"boolean\", \"description\": \"True if agent uses wrong parameter names, wrong data types, wrong structure (missing required keys, extra nesting), uses a field not accepted by the tool, OR maps data to the wrong field when a more appropriate field exists.\"},\n",
        "                        \"explanation\": {\"type\": \"string\", \"description\": \"Brief summary of the issue (or why none were found).\"},\n",
        "                        \"example\": {\"type\": \"string\", \"description\": \"One concrete example from the trace (or 'N/A' if none).\"}\n",
        "                    },\n",
        "                    \"required\": [\"present\", \"explanation\", \"example\"]\n",
        "                },\n",
        "                \"format_errors\": {\n",
        "                    \"type\": \"object\",\n",
        "                    \"additionalProperties\": False,\n",
        "                    \"properties\": {\n",
        "                        \"present\": {\"type\": \"boolean\", \"description\": \"True if agent produces unparseable or malformed tool output: invalid JSON, truncation, or mixing natural language into machine-readable payloads.\"},\n",
        "                        \"explanation\": {\"type\": \"string\", \"description\": \"Brief summary of the issue (or why none were found).\"},\n",
        "                        \"example\": {\"type\": \"string\", \"description\": \"One concrete example from the trace (or 'N/A' if none).\"}\n",
        "                    },\n",
        "                    \"required\": [\"present\", \"explanation\", \"example\"]\n",
        "                },\n",
        "                \"code_errors\": {\n",
        "                    \"type\": \"object\",\n",
        "                    \"additionalProperties\": False,\n",
        "                    \"properties\": {\n",
        "                        \"present\": {\"type\": \"boolean\", \"description\": \"True if valid tool calls fail during execution: Bash syntax errors, runtime exceptions (NameError, ImportError), logic bugs, or environment misconceptions.\"},\n",
        "                        \"explanation\": {\"type\": \"string\", \"description\": \"Brief summary of the issue (or why none were found).\"},\n",
        "                        \"example\": {\"type\": \"string\", \"description\": \"One concrete example from the trace (or 'N/A' if none).\"}\n",
        "                    },\n",
        "                    \"required\": [\"present\", \"explanation\", \"example\"]\n",
        "                }\n",
        "            },\n",
        "            \"required\": [\"endpoint_selection\", \"parameter_misuse\", \"format_errors\", \"code_errors\"]\n",
        "        },\n",
        "        \"model_refusal\": {\n",
        "            \"type\": \"object\",\n",
        "            \"additionalProperties\": False,\n",
        "            \"properties\": {\n",
        "                \"present\": {\"type\": \"boolean\", \"description\": \"True if agent refuses to act, asks user for info it could retrieve, OR delegates execution back to user by providing recommendations instead of performing actions itself (passive summary instead of active task completion).\"},\n",
        "                \"explanation\": {\"type\": \"string\", \"description\": \"Brief summary of the refusal (or why none were found).\"},\n",
        "                \"example\": {\"type\": \"string\", \"description\": \"One concrete example from the trace (or 'N/A' if none).\"}\n",
        "            },\n",
        "            \"required\": [\"present\", \"explanation\", \"example\"]\n",
        "        },\n",
        "        \n",
        "        \"hallucination_errors\": {\n",
        "            \"type\": \"object\",\n",
        "            \"description\": \"Hallucination errors where the agent fabricates or asserts invented information as truth. Distinct from reasoning errors (logic failures) and assumption errors (guessing without checking).\",\n",
        "            \"additionalProperties\": False,\n",
        "            \"properties\": {\n",
        "                \"parameter_hallucination\": {\n",
        "                    \"type\": \"object\",\n",
        "                    \"additionalProperties\": False,\n",
        "                    \"properties\": {\n",
        "                        \"present\": {\"type\": \"boolean\", \"description\": \"True if agent asserts invented parameter values (IDs, names, timestamps, URLs, file IDs) as truth, not grounded in trace or user input.\"},\n",
        "                        \"example\": {\"type\": \"string\", \"description\": \"Concrete example from trace (or 'N/A' if none).\"}\n",
        "                    },\n",
        "                    \"required\": [\"present\", \"example\"]\n",
        "                },\n",
        "                \"outcome_hallucination\": {\n",
        "                    \"type\": \"object\",\n",
        "                    \"additionalProperties\": False,\n",
        "                    \"properties\": {\n",
        "                        \"present\": {\"type\": \"boolean\", \"description\": \"True if agent falsely claims task completion or success despite evidence showing it was not completed.\"},\n",
        "                        \"example\": {\"type\": \"string\", \"description\": \"Concrete example from trace (or 'N/A' if none).\"}\n",
        "                    },\n",
        "                    \"required\": [\"present\", \"example\"]\n",
        "                },\n",
        "                \"state_hallucination\": {\n",
        "                    \"type\": \"object\",\n",
        "                    \"additionalProperties\": False,\n",
        "                    \"properties\": {\n",
        "                        \"present\": {\"type\": \"boolean\", \"description\": \"True if agent fabricates/invents state that doesn't exist (e.g., 'the file was created' when it wasn't, 'the user exists' without checking). Distinct from state_tracking_error which is forgetting.\"},\n",
        "                        \"example\": {\"type\": \"string\", \"description\": \"Concrete example from trace (or 'N/A' if none).\"}\n",
        "                    },\n",
        "                    \"required\": [\"present\", \"example\"]\n",
        "                },\n",
        "                \"action_hallucination\": {\n",
        "                    \"type\": \"object\",\n",
        "                    \"additionalProperties\": False,\n",
        "                    \"properties\": {\n",
        "                        \"present\": {\"type\": \"boolean\", \"description\": \"True if agent claims to have performed an action (read file, made API call, executed command) that doesn't appear in the trace. Fabricating execution of steps.\"},\n",
        "                        \"example\": {\"type\": \"string\", \"description\": \"Concrete example from trace (or 'N/A' if none).\"}\n",
        "                    },\n",
        "                    \"required\": [\"present\", \"example\"]\n",
        "                },\n",
        "                \"capability_hallucination\": {\n",
        "                    \"type\": \"object\",\n",
        "                    \"additionalProperties\": False,\n",
        "                    \"properties\": {\n",
        "                        \"present\": {\"type\": \"boolean\", \"description\": \"True if agent believes a tool/API can do something it cannot, or invents non-existent tool capabilities/endpoints.\"},\n",
        "                        \"example\": {\"type\": \"string\", \"description\": \"Concrete example from trace (or 'N/A' if none).\"}\n",
        "                    },\n",
        "                    \"required\": [\"present\", \"example\"]\n",
        "                },\n",
        "                \"context_hallucination\": {\n",
        "                    \"type\": \"object\",\n",
        "                    \"additionalProperties\": False,\n",
        "                    \"properties\": {\n",
        "                        \"present\": {\"type\": \"boolean\", \"description\": \"True if agent references information not present in trace, prompt, or API responses, asserting invented context as truth.\"},\n",
        "                        \"example\": {\"type\": \"string\", \"description\": \"Concrete example from trace (or 'N/A' if none).\"}\n",
        "                    },\n",
        "                    \"required\": [\"present\", \"example\"]\n",
        "                },\n",
        "                \"other_hallucination\": {\n",
        "                    \"type\": \"object\",\n",
        "                    \"additionalProperties\": False,\n",
        "                    \"properties\": {\n",
        "                        \"present\": {\"type\": \"boolean\", \"description\": \"True if there is a hallucination not covered by other categories.\"},\n",
        "                        \"explanation\": {\"type\": \"string\", \"description\": \"Description of the hallucination type (or 'N/A' if none).\"},\n",
        "                        \"example\": {\"type\": \"string\", \"description\": \"Concrete example from trace (or 'N/A' if none).\"}\n",
        "                    },\n",
        "                    \"required\": [\"present\", \"explanation\", \"example\"]\n",
        "                }\n",
        "            },\n",
        "            \"required\": [\"parameter_hallucination\", \"outcome_hallucination\", \"state_hallucination\", \"action_hallucination\", \"capability_hallucination\", \"context_hallucination\", \"other_hallucination\"]\n",
        "        },\n",
        "        \"reasoning_errors\": {\n",
        "            \"type\": \"object\",\n",
        "            \"description\": \"Reasoning errors involving logic failures, memory issues, or flawed inference. Distinct from hallucinations (fabricating facts) - reasoning errors are about HOW the agent thinks, not inventing information.\",\n",
        "            \"additionalProperties\": False,\n",
        "            \"properties\": {\n",
        "                \"time_orientation_error\": {\n",
        "                    \"type\": \"object\",\n",
        "                    \"additionalProperties\": False,\n",
        "                    \"properties\": {\n",
        "                        \"present\": {\"type\": \"boolean\", \"description\": \"True if agent confused past/future events, made date/time calculation errors, had timezone issues, or misunderstood 'now' vs scheduled times.\"},\n",
        "                        \"example\": {\"type\": \"string\", \"description\": \"Concrete example from trace (or 'N/A' if none).\"}\n",
        "                    },\n",
        "                    \"required\": [\"present\", \"example\"]\n",
        "                },\n",
        "                \"state_tracking_error\": {\n",
        "                    \"type\": \"object\",\n",
        "                    \"additionalProperties\": False,\n",
        "                    \"properties\": {\n",
        "                        \"present\": {\"type\": \"boolean\", \"description\": \"True if agent FORGOT previous actions, failed to update understanding after new information, or repeated already-completed actions (memory failure). Distinct from state_hallucination which is FABRICATING state.\"},\n",
        "                        \"example\": {\"type\": \"string\", \"description\": \"Concrete example from trace (or 'N/A' if none).\"}\n",
        "                    },\n",
        "                    \"required\": [\"present\", \"example\"]\n",
        "                },\n",
        "                \"goal_misalignment_error\": {\n",
        "                    \"type\": \"object\",\n",
        "                    \"additionalProperties\": False,\n",
        "                    \"properties\": {\n",
        "                        \"present\": {\"type\": \"boolean\", \"description\": \"True if agent solved wrong problem, missed implicit requirements, over/under-interpreted intent, optimized for wrong goal, OR understood an explicit requirement but deprioritized/ignored it (e.g., knew batching was required but chose individual calls anyway).\"},\n",
        "                        \"example\": {\"type\": \"string\", \"description\": \"Concrete example from trace (or 'N/A' if none).\"}\n",
        "                    },\n",
        "                    \"required\": [\"present\", \"example\"]\n",
        "                },\n",
        "                \"causal_reasoning_error\": {\n",
        "                    \"type\": \"object\",\n",
        "                    \"additionalProperties\": False,\n",
        "                    \"properties\": {\n",
        "                        \"present\": {\"type\": \"boolean\", \"description\": \"True if agent misattributed failure cause, reversed cause/effect, or missed causal steps.\"},\n",
        "                        \"example\": {\"type\": \"string\", \"description\": \"Concrete example from trace (or 'N/A' if none).\"}\n",
        "                    },\n",
        "                    \"required\": [\"present\", \"example\"]\n",
        "                },\n",
        "                \"confirmation_bias\": {\n",
        "                    \"type\": \"object\",\n",
        "                    \"additionalProperties\": False,\n",
        "                    \"properties\": {\n",
        "                        \"present\": {\"type\": \"boolean\", \"description\": \"True if agent ignored contradictory error messages, persisted with failing approach despite clear feedback, or selectively interpreted results.\"},\n",
        "                        \"example\": {\"type\": \"string\", \"description\": \"Concrete example from trace (or 'N/A' if none).\"}\n",
        "                    },\n",
        "                    \"required\": [\"present\", \"example\"]\n",
        "                },\n",
        "                \"logical_fallacy\": {\n",
        "                    \"type\": \"object\",\n",
        "                    \"additionalProperties\": False,\n",
        "                    \"properties\": {\n",
        "                        \"present\": {\"type\": \"boolean\", \"description\": \"True if agent used false dichotomy (only 2 options when more exist), circular reasoning, or non sequitur conclusions (action doesn't follow from evidence).\"},\n",
        "                        \"example\": {\"type\": \"string\", \"description\": \"Concrete example from trace (or 'N/A' if none).\"}\n",
        "                    },\n",
        "                    \"required\": [\"present\", \"example\"]\n",
        "                },\n",
        "                \"assumption_error\": {\n",
        "                    \"type\": \"object\",\n",
        "                    \"additionalProperties\": False,\n",
        "                    \"properties\": {\n",
        "                        \"present\": {\"type\": \"boolean\", \"description\": \"True if agent GUESSED defaults, user preferences, or API behavior WITHOUT CHECKING. Distinct from hallucination which is asserting invented facts as known truth.\"},\n",
        "                        \"example\": {\"type\": \"string\", \"description\": \"Concrete example from trace (or 'N/A' if none).\"}\n",
        "                    },\n",
        "                    \"required\": [\"present\", \"example\"]\n",
        "                },\n",
        "                \"negation_error\": {\n",
        "                    \"type\": \"object\",\n",
        "                    \"additionalProperties\": False,\n",
        "                    \"properties\": {\n",
        "                        \"present\": {\"type\": \"boolean\", \"description\": \"True if agent inverted boolean conditions, misunderstood not/except/exclude, or did the opposite of requested.\"},\n",
        "                        \"example\": {\"type\": \"string\", \"description\": \"Concrete example from trace (or 'N/A' if none).\"}\n",
        "                    },\n",
        "                    \"required\": [\"present\", \"example\"]\n",
        "                },\n",
        "                \"scope_generalization_error\": {\n",
        "                    \"type\": \"object\",\n",
        "                    \"additionalProperties\": False,\n",
        "                    \"properties\": {\n",
        "                        \"present\": {\"type\": \"boolean\", \"description\": \"True if agent over-generalized from specific instructions, was too literal (missing spirit of request), or applied patterns from unrelated contexts.\"},\n",
        "                        \"example\": {\"type\": \"string\", \"description\": \"Concrete example from trace (or 'N/A' if none).\"}\n",
        "                    },\n",
        "                    \"required\": [\"present\", \"example\"]\n",
        "                },\n",
        "                \"dependency_ordering_error\": {\n",
        "                    \"type\": \"object\",\n",
        "                    \"additionalProperties\": False,\n",
        "                    \"properties\": {\n",
        "                        \"present\": {\"type\": \"boolean\", \"description\": \"True if agent performed actions in wrong SEQUENCE (e.g., tried to use result before fetching it, called API before authentication). About ordering, NOT about missing steps.\"},\n",
        "                        \"example\": {\"type\": \"string\", \"description\": \"Concrete example from trace (or 'N/A' if none).\"}\n",
        "                    },\n",
        "                    \"required\": [\"present\", \"example\"]\n",
        "                },\n",
        "                \"incomplete_execution_error\": {\n",
        "                    \"type\": \"object\",\n",
        "                    \"additionalProperties\": False,\n",
        "                    \"properties\": {\n",
        "                        \"present\": {\"type\": \"boolean\", \"description\": \"True if agent understood and planned required subtasks but failed to attempt some of them entirely (never tried). About OMISSION of steps, not wrong ordering.\"},\n",
        "                        \"example\": {\"type\": \"string\", \"description\": \"Concrete example from trace (or 'N/A' if none).\"}\n",
        "                    },\n",
        "                    \"required\": [\"present\", \"example\"]\n",
        "                },\n",
        "                \"premature_termination_error\": {\n",
        "                    \"type\": \"object\",\n",
        "                    \"additionalProperties\": False,\n",
        "                    \"properties\": {\n",
        "                        \"present\": {\"type\": \"boolean\", \"description\": \"True if agent stops execution and concludes the task before completing all required steps, without recognizing that more work remains. Distinct from incomplete_execution (planned but didn't attempt) - this is stopping early without awareness of remaining work.\"},\n",
        "                        \"example\": {\"type\": \"string\", \"description\": \"Concrete example from trace (or 'N/A' if none).\"}\n",
        "                    },\n",
        "                    \"required\": [\"present\", \"example\"]\n",
        "                },\n",
        "                \"quantitative_reasoning_error\": {\n",
        "                    \"type\": \"object\",\n",
        "                    \"additionalProperties\": False,\n",
        "                    \"properties\": {\n",
        "                        \"present\": {\"type\": \"boolean\", \"description\": \"True if agent made off-by-one errors, unit/scale confusion, incorrect aggregation (sum vs count), OR incorrect sorting/ordering of data (e.g., skipped items, wrong alphabetical order).\"},\n",
        "                        \"example\": {\"type\": \"string\", \"description\": \"Concrete example from trace (or 'N/A' if none).\"}\n",
        "                    },\n",
        "                    \"required\": [\"present\", \"example\"]\n",
        "                },\n",
        "                \"reference_resolution_error\": {\n",
        "                    \"type\": \"object\",\n",
        "                    \"additionalProperties\": False,\n",
        "                    \"properties\": {\n",
        "                        \"present\": {\"type\": \"boolean\", \"description\": \"True if agent misunderstood it/this/that references, confused similar entities, or lost track of objects.\"},\n",
        "                        \"example\": {\"type\": \"string\", \"description\": \"Concrete example from trace (or 'N/A' if none).\"}\n",
        "                    },\n",
        "                    \"required\": [\"present\", \"example\"]\n",
        "                },\n",
        "                \"instruction_fidelity_error\": {\n",
        "                    \"type\": \"object\",\n",
        "                    \"additionalProperties\": False,\n",
        "                    \"properties\": {\n",
        "                        \"present\": {\"type\": \"boolean\", \"description\": \"True if agent deviated from explicit instructions by modifying content that should be preserved verbatim (e.g., changing punctuation like em-dash to hyphen, rewording text) OR adding unrequested embellishments/formatting (e.g., numbering, introductions, author attributions, extra metadata) when literal execution was required.\"},\n",
        "                        \"example\": {\"type\": \"string\", \"description\": \"Concrete example from trace (or 'N/A' if none).\"}\n",
        "                    },\n",
        "                    \"required\": [\"present\", \"example\"]\n",
        "                },\n",
        "                \"reasoning_action_mismatch\": {\n",
        "                    \"type\": \"object\",\n",
        "                    \"additionalProperties\": False,\n",
        "                    \"properties\": {\n",
        "                        \"present\": {\"type\": \"boolean\", \"description\": \"True if agent's explicit reasoning/plan contradicts the action it actually executes. The agent 'knows' or states the correct approach but then does something different (e.g., reasons 'should use rich_text_section' but then uses 'text' type).\"},\n",
        "                        \"example\": {\"type\": \"string\", \"description\": \"Concrete example from trace (or 'N/A' if none).\"}\n",
        "                    },\n",
        "                    \"required\": [\"present\", \"example\"]\n",
        "                },\n",
        "                \"other_reasoning_error\": {\n",
        "                    \"type\": \"object\",\n",
        "                    \"additionalProperties\": False,\n",
        "                    \"properties\": {\n",
        "                        \"present\": {\"type\": \"boolean\", \"description\": \"True if there is a reasoning error not covered by other categories.\"},\n",
        "                        \"explanation\": {\"type\": \"string\", \"description\": \"Description of the reasoning error type (or 'N/A' if none).\"},\n",
        "                        \"example\": {\"type\": \"string\", \"description\": \"Concrete example from trace (or 'N/A' if none).\"}\n",
        "                    },\n",
        "                    \"required\": [\"present\", \"explanation\", \"example\"]\n",
        "                },\n",
        "                \"infinite_loop_error\": {\n",
        "                    \"type\": \"object\",\n",
        "                    \"additionalProperties\": False,\n",
        "                    \"properties\": {\n",
        "                        \"present\": {\"type\": \"boolean\", \"description\": \"True if agent gets stuck in pathological loop, repeating identical or near-identical reasoning and actions across multiple iterations without making progress or attempting meaningfully different approaches.\"},\n",
        "                        \"explanation\": {\"type\": \"string\", \"description\": \"Brief summary of the loop behavior (or why none were found).\"},\n",
        "                        \"example\": {\"type\": \"string\", \"description\": \"One concrete example from the trace (or 'N/A' if none).\"}\n",
        "                    },\n",
        "                    \"required\": [\"present\", \"explanation\", \"example\"]\n",
        "                }\n",
        "            },\n",
        "            \"required\": [\"time_orientation_error\", \"state_tracking_error\", \"goal_misalignment_error\", \"causal_reasoning_error\", \"confirmation_bias\", \"logical_fallacy\", \"assumption_error\", \"negation_error\", \"scope_generalization_error\", \"dependency_ordering_error\", \"incomplete_execution_error\", \"premature_termination_error\", \"quantitative_reasoning_error\", \"reference_resolution_error\", \"instruction_fidelity_error\", \"reasoning_action_mismatch\", \"other_reasoning_error\", \"infinite_loop_error\"]\n",
        "        },\n",
        "        \"recovery_strategies\": {\n",
        "            \"type\": \"object\",\n",
        "            \"description\": \"Recovery strategies the agent attempted. Evaluate each category explicitly.\",\n",
        "            \"additionalProperties\": False,\n",
        "            \"properties\": {\n",
        "                \"retry_same\": {\n",
        "                    \"type\": \"object\",\n",
        "                    \"additionalProperties\": False,\n",
        "                    \"properties\": {\n",
        "                        \"present\": {\"type\": \"boolean\", \"description\": \"True if agent retried the exact same action unchanged, hoping for different result.\"},\n",
        "                        \"example\": {\"type\": \"string\", \"description\": \"Concrete example from trace (or 'N/A' if none).\"}\n",
        "                    },\n",
        "                    \"required\": [\"present\", \"example\"]\n",
        "                },\n",
        "                \"retry_modified_params\": {\n",
        "                    \"type\": \"object\",\n",
        "                    \"additionalProperties\": False,\n",
        "                    \"properties\": {\n",
        "                        \"present\": {\"type\": \"boolean\", \"description\": \"True if agent retried with adjusted parameters (different ID, format, value).\"},\n",
        "                        \"example\": {\"type\": \"string\", \"description\": \"Concrete example from trace (or 'N/A' if none).\"}\n",
        "                    },\n",
        "                    \"required\": [\"present\", \"example\"]\n",
        "                },\n",
        "                \"switch_tool\": {\n",
        "                    \"type\": \"object\",\n",
        "                    \"additionalProperties\": False,\n",
        "                    \"properties\": {\n",
        "                        \"present\": {\"type\": \"boolean\", \"description\": \"True if agent switched to a different tool/endpoint to achieve the same goal.\"},\n",
        "                        \"example\": {\"type\": \"string\", \"description\": \"Concrete example from trace (or 'N/A' if none).\"}\n",
        "                    },\n",
        "                    \"required\": [\"present\", \"example\"]\n",
        "                },\n",
        "                \"lookup_correct_value\": {\n",
        "                    \"type\": \"object\",\n",
        "                    \"additionalProperties\": False,\n",
        "                    \"properties\": {\n",
        "                        \"present\": {\"type\": \"boolean\", \"description\": \"True if agent searched or queried to find the correct ID/name/value.\"},\n",
        "                        \"example\": {\"type\": \"string\", \"description\": \"Concrete example from trace (or 'N/A' if none).\"}\n",
        "                    },\n",
        "                    \"required\": [\"present\", \"example\"]\n",
        "                },\n",
        "                \"backtrack\": {\n",
        "                    \"type\": \"object\",\n",
        "                    \"additionalProperties\": False,\n",
        "                    \"properties\": {\n",
        "                        \"present\": {\"type\": \"boolean\", \"description\": \"True if agent returned to an earlier step to gather missing information.\"},\n",
        "                        \"example\": {\"type\": \"string\", \"description\": \"Concrete example from trace (or 'N/A' if none).\"}\n",
        "                    },\n",
        "                    \"required\": [\"present\", \"example\"]\n",
        "                },\n",
        "                \"parse_error_message\": {\n",
        "                    \"type\": \"object\",\n",
        "                    \"additionalProperties\": False,\n",
        "                    \"properties\": {\n",
        "                        \"present\": {\"type\": \"boolean\", \"description\": \"True if agent extracted useful info from error output to inform next action.\"},\n",
        "                        \"example\": {\"type\": \"string\", \"description\": \"Concrete example from trace (or 'N/A' if none).\"}\n",
        "                    },\n",
        "                    \"required\": [\"present\", \"example\"]\n",
        "                },\n",
        "                \"handle_ui_obstacle\": {\n",
        "                    \"type\": \"object\",\n",
        "                    \"additionalProperties\": False,\n",
        "                    \"properties\": {\n",
        "                        \"present\": {\"type\": \"boolean\", \"description\": \"True if agent handled popup, dialog, login wall, or similar UI blocker.\"},\n",
        "                        \"example\": {\"type\": \"string\", \"description\": \"Concrete example from trace (or 'N/A' if none).\"}\n",
        "                    },\n",
        "                    \"required\": [\"present\", \"example\"]\n",
        "                },\n",
        "                \"change_strategy\": {\n",
        "                    \"type\": \"object\",\n",
        "                    \"additionalProperties\": False,\n",
        "                    \"properties\": {\n",
        "                        \"present\": {\"type\": \"boolean\", \"description\": \"True if agent abandoned current approach entirely and tried a different method.\"},\n",
        "                        \"example\": {\"type\": \"string\", \"description\": \"Concrete example from trace (or 'N/A' if none).\"}\n",
        "                    },\n",
        "                    \"required\": [\"present\", \"example\"]\n",
        "                },\n",
        "                \"break_into_steps\": {\n",
        "                    \"type\": \"object\",\n",
        "                    \"additionalProperties\": False,\n",
        "                    \"properties\": {\n",
        "                        \"present\": {\"type\": \"boolean\", \"description\": \"True if agent decomposed a complex action into smaller sequential steps.\"},\n",
        "                        \"example\": {\"type\": \"string\", \"description\": \"Concrete example from trace (or 'N/A' if none).\"}\n",
        "                    },\n",
        "                    \"required\": [\"present\", \"example\"]\n",
        "                },\n",
        "                \"verify_prerequisites\": {\n",
        "                    \"type\": \"object\",\n",
        "                    \"additionalProperties\": False,\n",
        "                    \"properties\": {\n",
        "                        \"present\": {\"type\": \"boolean\", \"description\": \"True if agent checked if required conditions were met before retrying.\"},\n",
        "                        \"example\": {\"type\": \"string\", \"description\": \"Concrete example from trace (or 'N/A' if none).\"}\n",
        "                    },\n",
        "                    \"required\": [\"present\", \"example\"]\n",
        "                },\n",
        "                \"skip_and_continue\": {\n",
        "                    \"type\": \"object\",\n",
        "                    \"additionalProperties\": False,\n",
        "                    \"properties\": {\n",
        "                        \"present\": {\"type\": \"boolean\", \"description\": \"True if agent moved past a blocking item to complete other parts of task.\"},\n",
        "                        \"example\": {\"type\": \"string\", \"description\": \"Concrete example from trace (or 'N/A' if none).\"}\n",
        "                    },\n",
        "                    \"required\": [\"present\", \"example\"]\n",
        "                },\n",
        "                \"wait_and_retry\": {\n",
        "                    \"type\": \"object\",\n",
        "                    \"additionalProperties\": False,\n",
        "                    \"properties\": {\n",
        "                        \"present\": {\"type\": \"boolean\", \"description\": \"True if agent added delay for rate limits or async operations.\"},\n",
        "                        \"example\": {\"type\": \"string\", \"description\": \"Concrete example from trace (or 'N/A' if none).\"}\n",
        "                    },\n",
        "                    \"required\": [\"present\", \"example\"]\n",
        "                },\n",
        "                \"use_fallback\": {\n",
        "                    \"type\": \"object\",\n",
        "                    \"additionalProperties\": False,\n",
        "                    \"properties\": {\n",
        "                        \"present\": {\"type\": \"boolean\", \"description\": \"True if agent used a secondary/backup method when primary failed.\"},\n",
        "                        \"example\": {\"type\": \"string\", \"description\": \"Concrete example from trace (or 'N/A' if none).\"}\n",
        "                    },\n",
        "                    \"required\": [\"present\", \"example\"]\n",
        "                },\n",
        "                \"other_recovery_strategy\": {\n",
        "                    \"type\": \"object\",\n",
        "                    \"additionalProperties\": False,\n",
        "                    \"properties\": {\n",
        "                        \"present\": {\"type\": \"boolean\", \"description\": \"True if agent used a recovery strategy not covered by other categories.\"},\n",
        "                        \"explanation\": {\"type\": \"string\", \"description\": \"Description of the recovery strategy (or 'N/A' if none).\"},\n",
        "                        \"example\": {\"type\": \"string\", \"description\": \"Concrete example from trace (or 'N/A' if none).\"}\n",
        "                    },\n",
        "                    \"required\": [\"present\", \"explanation\", \"example\"]\n",
        "                },\n",
        "                \"no_recovery_attempted\": {\n",
        "                    \"type\": \"object\",\n",
        "                    \"additionalProperties\": False,\n",
        "                    \"properties\": {\n",
        "                        \"present\": {\"type\": \"boolean\", \"description\": \"True if agent gave up immediately or got stuck in a loop without any recovery attempt.\"},\n",
        "                        \"example\": {\"type\": \"string\", \"description\": \"Concrete example from trace (or 'N/A' if none).\"}\n",
        "                    },\n",
        "                    \"required\": [\"present\", \"example\"]\n",
        "                }\n",
        "            },\n",
        "            \"required\": [\"retry_same\", \"retry_modified_params\", \"switch_tool\", \"lookup_correct_value\", \"backtrack\", \"parse_error_message\", \"handle_ui_obstacle\", \"change_strategy\", \"break_into_steps\", \"verify_prerequisites\", \"skip_and_continue\", \"wait_and_retry\", \"use_fallback\", \"other_recovery_strategy\", \"no_recovery_attempted\"]\n",
        "        },\n",
        "        \"other_error\": {\n",
        "            \"type\": \"object\",\n",
        "            \"additionalProperties\": False,\n",
        "            \"properties\": {\n",
        "                \"present\": {\"type\": \"boolean\", \"description\": \"True if there is an error that doesn't fit other categories.\"},\n",
        "                \"explanation\": {\"type\": \"string\", \"description\": \"Brief summary of the issue, including a proposed subcategory for this error type.\"},\n",
        "                \"example\": {\"type\": \"string\", \"description\": \"One concrete example from the trace (or 'N/A' if none).\"}\n",
        "            },\n",
        "            \"required\": [\"present\", \"explanation\", \"example\"]\n",
        "        },\n",
        "        \"qualitative_summary\": {\n",
        "            \"type\": \"object\",\n",
        "            \"additionalProperties\": False,\n",
        "            \"properties\": {\n",
        "                \"planning_score\": {\n",
        "                    \"type\": \"integer\",\n",
        "                    \"minimum\": 0,\n",
        "                    \"maximum\": 5,\n",
        "                    \"description\": \"Planning quality (0-5): action sequencing, adaptation to obstacles, and efficiency of approach.\"\n",
        "                },\n",
        "                \"planning_explanation\": {\n",
        "                    \"type\": \"string\",\n",
        "                    \"description\": \"Brief justification for the planning score, including any efficiency issues.\"\n",
        "                },\n",
        "                \"reasoning_score\": {\n",
        "                    \"type\": \"integer\",\n",
        "                    \"minimum\": 0,\n",
        "                    \"maximum\": 5,\n",
        "                    \"description\": \"Reasoning quality (0-5): correctness of inferences, use of context, and sound logic in decision-making.\"\n",
        "                },\n",
        "                \"reasoning_explanation\": {\n",
        "                    \"type\": \"string\",\n",
        "                    \"description\": \"Brief justification for the reasoning score, noting any flawed inferences or logic errors.\"\n",
        "                },\n",
        "                \"tool_use_score\": {\n",
        "                    \"type\": \"integer\",\n",
        "                    \"minimum\": 0,\n",
        "                    \"maximum\": 5,\n",
        "                    \"description\": \"API/tool handling quality (0-5): endpoint selection, parameter formatting, error handling, and response parsing.\"\n",
        "                },\n",
        "                \"tool_use_explanation\": {\n",
        "                    \"type\": \"string\",\n",
        "                    \"description\": \"Brief justification for the tool use score, noting any API misuse or parameter errors.\"\n",
        "                },\n",
        "                \"recovery_score\": {\n",
        "                    \"type\": \"integer\",\n",
        "                    \"minimum\": 0,\n",
        "                    \"maximum\": 5,\n",
        "                    \"description\": \"Recovery ability (0-5): failure detection, root cause diagnosis, and applying corrective strategies.\"\n",
        "                },\n",
        "                \"recovery_explanation\": {\n",
        "                    \"type\": \"string\",\n",
        "                    \"description\": \"Brief justification for the recovery score, noting recovery strategies used or missed opportunities.\"\n",
        "                },\n",
        "                \"hallucination_score\": {\n",
        "                    \"type\": \"integer\",\n",
        "                    \"minimum\": 0,\n",
        "                    \"maximum\": 5,\n",
        "                    \"description\": \"Hallucination resistance (0-5): degree to which agent avoids fabricating information, inventing facts, or asserting false claims.\"\n",
        "                },\n",
        "                \"hallucination_explanation\": {\n",
        "                    \"type\": \"string\",\n",
        "                    \"description\": \"Brief justification for the hallucination score, noting any fabricated information or false claims.\"\n",
        "                },\n",
        "                \"overall_description\": {\n",
        "                    \"type\": \"string\",\n",
        "                    \"description\": \"2-3 sentence high-level narrative of what went wrong and why, suitable for a paper's qualitative analysis section\"\n",
        "                },\n",
        "                \"key_insight\": {\n",
        "                    \"type\": \"string\",\n",
        "                    \"description\": \"The single most important takeaway from analyzing this run\"\n",
        "                },\n",
        "                \"model_behavior_pattern\": {\n",
        "                    \"type\": \"string\",\n",
        "                    \"description\": \"What does this run reveal about how the model approaches this type of task?\"\n",
        "                },\n",
        "                \"implications_for_reliability\": {\n",
        "                    \"type\": \"string\",\n",
        "                    \"description\": \"What does this failure reveal about model reliability/robustness?\"\n",
        "                },\n",
        "                \"worthy_example\": {\n",
        "                    \"type\": \"boolean\",\n",
        "                    \"description\": \"Is this run interesting enough to feature in the qualitative analysis?\"\n",
        "                },\n",
        "                \"why_worthy_example\": {\n",
        "                    \"type\": \"string\",\n",
        "                    \"description\": \"If worthy_example is true, explain why this example is noteworthy (or 'N/A' if not worthy)\"\n",
        "                }\n",
        "            },\n",
        "            \"required\": [\"planning_score\", \"planning_explanation\", \"reasoning_score\", \"reasoning_explanation\", \"tool_use_score\", \"tool_use_explanation\", \"recovery_score\", \"recovery_explanation\", \"hallucination_score\", \"hallucination_explanation\", \"overall_description\", \"key_insight\", \"model_behavior_pattern\", \"implications_for_reliability\", \"worthy_example\", \"why_worthy_example\"]\n",
        "        }\n",
        "    },\n",
        "    \"required\": [\n",
        "        \"tool_use_errors\",\n",
        "        \"model_refusal\",\n",
        "        \"hallucination_errors\",\n",
        "        \"reasoning_errors\",\n",
        "        \"recovery_strategies\",\n",
        "        \"other_error\",\n",
        "        \"qualitative_summary\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "\n",
        "def construct_run_analysis_prompt_elements(cur_run_score, other_run_type, other_run_score):\n",
        "    \n",
        "    SYSTEM_MSG = f\"You are a helpful assistant. You are required to analyze RUN_TO_ANALYZE and compare it to {other_run_type} as a reference.\\n\"\n",
        "    \n",
        "    HUMAN_MSG_CUR_RUN = \"Here is the RUN_TO_ANALYZE:\\n\"\n",
        "    \n",
        "    if other_run_type == \"ONE_OF_THE_BEST_RUNS\":\n",
        "        HUMAN_MSG_OTHER_RUN = f\"NOTE: RUN_TO_ANALYZE failed in the task with the score of {cur_run_score}/100.0. Unfortunately, no agent was able to finish the required task, which indicates that the task is likely very hard. However, here is ONE_OF_THE_BEST_RUNS (use it only as a reference of what an alternative approach could look like; NOTE: ONE_OF_THE_BEST_RUNS also failed with the score of {other_run_score}/100.0):\\n\"\n",
        "    \n",
        "    elif other_run_type == \"ANOTHER_SUCCESSFUL_RUN\":\n",
        "        HUMAN_MSG_OTHER_RUN = f\"NOTE: RUN_TO_ANALYZE succeeded in the task with the score of 100.0/100.0. However, here is ANOTHER_ONE_OF_THE_BEST_RUNS which finished with the score of {other_run_score}/100.0 (use it only as a reference of what an alternative approach could look like):\\n\"\n",
        "    \n",
        "    else: # other_run_type == \"BEST_RUN\":\n",
        "        HUMAN_MSG_OTHER_RUN = f\"NOTE: RUN_TO_ANALYZE failed in the task with the score of {cur_run_score}/100.0. However, here is ONE_OF_THE_BEST_RUNS, which succeeded with the score of {other_run_score}/100.0 (use as reference for what a correct approach looks like):\\n\"\n",
        "\n",
        "    RUN_ANALYSIS_PROMPT = f\"\"\"IMPORTANT EVALUATION CONTEXT:\n",
        "The agents being evaluated were given these instructions in their system prompt:\n",
        "- \"Use execute_bash to interact with [Service] API at [endpoint]. Complete the task using the tools provided.\"\n",
        "- \"Authentication is handled automatically via proxy. Leave a placeholder credential where you would add a real token.\"\n",
        "\n",
        "Therefore, do NOT flag as errors:\n",
        "- Agent not explicitly handling authentication (it's automatic via proxy)\n",
        "- Agent using placeholder credentials or assuming auth works\n",
        "- Agent proceeding directly to API calls without auth setup\n",
        "\n",
        "Now analyze RUN_TO_ANALYZE (and use {other_run_type} only as a reference for what a correct approach looks like). Evaluate the following categories in order. For each category, provide the required fields as specified.\n",
        "\n",
        "    1) Tool Use Errors\n",
        "    Errors related to how the agent interacts with tools and APIs. Evaluate each subtype explicitly:\n",
        "\n",
        "    endpoint_selection:\n",
        "    Determine whether the agent consistently selects correct endpoints to make progress toward the user's goal.\n",
        "    - present: True if there are any incorrect or irrelevant endpoint choices\n",
        "    - explanation: Brief summary of the issue (or why none were found)\n",
        "    - example: One concrete example from the trace (or 'N/A' if none)\n",
        "\n",
        "    parameter_misuse:\n",
        "    Determine whether the agent ever calls an API endpoint with incorrectly formatted, incorrectly typed, or semantically misplaced parameters.\n",
        "    This includes:\n",
        "    - Wrong parameter names\n",
        "    - Wrong data types (string vs int vs list vs object)\n",
        "    - Wrong structure (scalar where an object is required, missing required keys, extra nesting)\n",
        "    - Using a field not accepted by the tool when the correct accepted field exists\n",
        "    - Semantic field mapping errors: putting data in the wrong field when a more appropriate field exists (e.g., putting location info like \"Pearlwork Desk\" in summary field instead of the dedicated location field)\n",
        "    - present: True if there is any parameter misuse\n",
        "    - explanation: Brief summary of the issue (or why none were found)\n",
        "    - example: One concrete example from the trace, e.g., 'tool expects user_id: \"U123\" but agent passes user: \"sarah\"' or 'put location in summary instead of location field' (or 'N/A' if none)\n",
        "\n",
        "    format_errors:\n",
        "    Determine whether the agent ever produces tool-related output that is unparseable or malformed in a way that would prevent correct execution or structured parsing.\n",
        "    This includes invalid JSON (broken braces/quotes, trailing commas, partial JSON), incorrect field nesting that makes the payload unparsable, mixing natural language into a payload that must be machine-readable, truncation that cuts off the payload, or any syntax/format issue that causes the tool call or structured output to fail to parse.\n",
        "    - present: True if there is any unparseable or malformed payload\n",
        "    - explanation: Brief summary of the issue (or why none were found)\n",
        "    - example: One concrete example from the trace (or 'N/A' if none)\n",
        "\n",
        "    code_errors:\n",
        "    Determine whether the agent produces valid tool calls (e.g. valid JSON) but the content of the call (the script or command) fails during execution.\n",
        "    This includes Bash syntax errors, runtime exceptions (NameError, ImportError), logic bugs in the script, or environment misconceptions (e.g. assuming variables or files persist between isolated tool calls when they do not).\n",
        "    - present: True if code execution failed\n",
        "    - explanation: Brief summary of the issue (or why none were found)\n",
        "    - example: One concrete example from the trace, e.g., \"NameError: 'headers' is not defined\" (or 'N/A' if none)\n",
        "\n",
        "    2) Model Refusal\n",
        "    Determine whether the agent refuses to perform the task, asks the user for information it could retrieve itself, OR delegates execution back to user instead of acting.\n",
        "    This includes:\n",
        "    - Explicitly refusing to perform the task\n",
        "    - Asking user for IDs, tokens, or file contents that the agent could find itself\n",
        "    - Passive delegation: gathering information but providing recommendations for user to execute instead of performing actions itself (e.g., \"You should reach out to @user\" instead of actually sending the message)\n",
        "    - present: True if the agent declines, offloads work, or delegates execution to the user\n",
        "    - explanation: Brief summary of the refusal/delegation (or why none were found)\n",
        "    - example: One concrete example from the trace, e.g., \"'Please provide the user ID' when agent has a search tool\" or \"Provided summary with 'You can now message @user' but made no tool calls to do so\" (or 'N/A' if none)\n",
        "\n",
        "    3) Hallucination Errors\n",
        "    Hallucinations are when the agent FABRICATES or ASSERTS invented information as truth.\n",
        "    This is distinct from reasoning errors (logic/inference failures) and assumption errors (guessing without checking).\n",
        "    \n",
        "    For EACH of the following hallucination types, explicitly evaluate whether it occurred:\n",
        "    You MUST provide a judgment (present: true/false) and example for EVERY category:\n",
        "\n",
        "    - parameter_hallucination: Agent ASSERTS invented parameter values (IDs, names, timestamps, URLs, file IDs) as truth, when these values are not grounded in the trace or user input. Example: using channel ID \"C99999\" that never appeared anywhere.\n",
        "    - outcome_hallucination: Agent falsely CLAIMS task completion or success despite evidence showing the task was not actually completed.\n",
        "    - state_hallucination: Agent FABRICATES state that doesn't exist (e.g., \"the file was created\" when it wasn't, \"the user exists\" without any evidence). Distinct from state_tracking_error which is FORGETTING existing state.\n",
        "    - action_hallucination: Agent CLAIMS to have performed an action (read a file, made an API call, executed a command) that doesn't appear in the trace. Fabricating that execution occurred when it did not. Example: \"Content read: ...\" in reasoning but no corresponding API call in trace.\n",
        "    - capability_hallucination: Agent believes a tool/API can do something it cannot, or invents non-existent tool capabilities/endpoints.\n",
        "    - context_hallucination: Agent references information not present in trace, prompt, or API responses, asserting invented context as truth.\n",
        "    - other_hallucination: A hallucination not covered by the categories above (if present, provide explanation).\n",
        "\n",
        "    For each category, return:\n",
        "    - present: true/false\n",
        "    - example: Concrete example from trace (or 'N/A' if none)\n",
        "    - explanation: (ONLY for other_hallucination) Description of the hallucination type\n",
        "\n",
        "    4) Reasoning Errors\n",
        "    Reasoning errors involve logic failures, memory issues, or flawed inference.\n",
        "    These are about HOW the agent thinks, not about fabricating information (which is hallucination).\n",
        "    \n",
        "    IMPORTANT DISTINCTIONS:\n",
        "    - state_tracking_error = agent FORGETS what happened (memory failure)\n",
        "    - state_hallucination = agent INVENTS what happened (fabrication) → goes in hallucination_errors\n",
        "    - assumption_error = agent GUESSES without checking (uncertainty acknowledged implicitly)\n",
        "    - hallucination = agent ASSERTS invented facts as known truth (false certainty)\n",
        "    - dependency_ordering_error = agent does steps in wrong SEQUENCE\n",
        "    - incomplete_execution_error = agent OMITS steps entirely (never attempts them)\n",
        "    - premature_termination_error = agent STOPS early thinking task is done when it's not\n",
        "\n",
        "    For EACH of the following reasoning error types, explicitly evaluate whether it occurred:\n",
        "    You MUST provide a judgment (present: true/false) and example for EVERY category:\n",
        "\n",
        "    - time_orientation_error: Confusing past vs future events, incorrect date/time calculations, timezone confusion, misunderstanding \"now\" vs scheduled times\n",
        "    - state_tracking_error: Agent FORGOT previous actions, failed to update understanding after new information, or repeated already-completed actions (MEMORY failure, not fabrication)\n",
        "    - goal_misalignment_error: Solving a different problem than asked, missing implicit requirements, over/under-interpreting intent, optimizing for wrong goal, OR understanding an explicit requirement but deprioritizing/ignoring it (e.g., knew batching was required but chose individual calls anyway)\n",
        "    - causal_reasoning_error: Misattributing why something failed, reversing cause and effect, missing intermediate steps in causal chain\n",
        "    - confirmation_bias: Ignoring contradictory error messages, persisting with failing approach despite clear feedback, selective interpretation of results\n",
        "    - logical_fallacy: False dichotomy (only 2 options when more exist), circular reasoning, non sequitur conclusions (action doesn't follow from evidence)\n",
        "    - assumption_error: Agent GUESSED defaults, user preferences, or API behavior WITHOUT CHECKING first. This is making unverified assumptions, not asserting fabricated facts as truth.\n",
        "    - negation_error: Inverting boolean conditions, misunderstanding \"not\"/\"except\"/\"exclude\", doing the opposite of what's requested\n",
        "    - scope_generalization_error: Over-generalizing from specific instructions, being too literal (missing spirit of request), applying patterns from unrelated contexts\n",
        "    - dependency_ordering_error: Performing actions in wrong SEQUENCE (e.g., tried to use result before fetching it, called API before authentication). About ordering, NOT about missing steps.\n",
        "    - incomplete_execution_error: Agent understood and planned required subtasks but failed to attempt some of them entirely. About OMISSION of steps (never tried), not wrong ordering. Example: planned to grant access and copy events but only did one.\n",
        "    - premature_termination_error: Agent stops execution and concludes the task is complete before finishing all required steps, without recognizing that more work remains. Distinct from incomplete_execution (planned but didn't attempt) - this is stopping early without awareness. Example: task requires sending 3 messages but agent stops after sending 1 and says \"Done!\"\n",
        "    - quantitative_reasoning_error: Off-by-one errors, unit/scale confusion, incorrect aggregation (sum vs count), OR incorrect sorting/ordering of data (e.g., skipped items when sorting alphabetically, wrong sort order)\n",
        "    - reference_resolution_error: Misunderstanding what \"it\"/\"this\"/\"that\" refers to, confusing multiple similar entities, losing track of which object is discussed\n",
        "    - instruction_fidelity_error: Agent deviated from explicit instructions by modifying content that should be preserved verbatim (e.g., changing punctuation like em-dash to hyphen, rewording text) OR adding unrequested embellishments/formatting (e.g., numbering, introductions, author attributions, extra metadata) when literal execution was required.\n",
        "    - reasoning_action_mismatch: Agent's explicit reasoning/plan contradicts the action it actually executes. The agent \"knows\" or states the correct approach but then does something different (e.g., reasons \"should use rich_text_section\" but then uses \"text\" type).\n",
        "    - other_reasoning_error: A reasoning error not covered by the categories above (if present, provide explanation)\n",
        "    - infinite_loop_error: Agent gets stuck in pathological loop, repeating identical or near-identical reasoning and actions across multiple iterations without making progress or attempting meaningfully different approaches\n",
        "\n",
        "    For each category, return:\n",
        "    - present: true/false\n",
        "    - example: Concrete example from trace (or 'N/A' if none)\n",
        "    - explanation: (ONLY for other_reasoning_error and infinite_loop_error) Description of the error\n",
        "\n",
        "    5) Recovery Strategies\n",
        "    For EACH of the following recovery strategy types, explicitly evaluate whether the agent attempted it in RUN_TO_ANALYZE.\n",
        "    You MUST provide a judgment (present: true/false) and example for EVERY category:\n",
        "\n",
        "    - retry_same: Retried the exact same action unchanged, hoping for different result\n",
        "    - retry_modified_params: Retried with adjusted parameters (different ID, format, value)\n",
        "    - switch_tool: Switched to a different tool/endpoint to achieve the same goal\n",
        "    - lookup_correct_value: Searched or queried to find the correct ID/name/value\n",
        "    - backtrack: Returned to an earlier step to gather missing information\n",
        "    - parse_error_message: Extracted useful info from error output to inform next action\n",
        "    - handle_ui_obstacle: Handled popup, dialog, login wall, or similar UI blocker\n",
        "    - change_strategy: Abandoned current approach entirely, tried a different method\n",
        "    - break_into_steps: Decomposed a complex action into smaller sequential steps\n",
        "    - verify_prerequisites: Checked if required conditions were met before retrying\n",
        "    - skip_and_continue: Moved past a blocking item to complete other parts of task\n",
        "    - wait_and_retry: Added delay for rate limits or async operations\n",
        "    - use_fallback: Used a secondary/backup method when primary failed\n",
        "    - other_recovery_strategy: A recovery strategy not covered by the categories above (if present, provide explanation)\n",
        "    - no_recovery_attempted: Agent gave up immediately or got stuck in a loop without any recovery attempt\n",
        "\n",
        "    For each category, return:\n",
        "    - present: true/false\n",
        "    - example: Concrete example from trace (or 'N/A' if none)\n",
        "    - explanation: (ONLY for other_recovery_strategy) Description of the recovery strategy\n",
        "\n",
        "    6) Other Errors\n",
        "    Determine if there are any other errors not covered by the previous categories (1-4).\n",
        "    - present: True if there is an error that doesn't fit other categories\n",
        "    - explanation: Brief summary of the issue, including a proposed subcategory name (e.g., 'Timing Error', 'Resource Limit') (or 'No other errors found' if none)\n",
        "    - example: One concrete example from the trace (or 'N/A' if none)\n",
        "\n",
        "    7) Qualitative Summary\n",
        "    Provide a high-level narrative analysis of this run:\n",
        "    \n",
        "    First, evaluate planning quality:\n",
        "    - planning_score: Integer 0-5 for planning quality (action sequencing, adaptation to obstacles, efficiency)\n",
        "      Score scale:\n",
        "      - 5 = Excellent: clear, efficient action sequence; proactively handles obstacles; quickly switches strategy when blocked; uses optimal API patterns (batch calls when available).\n",
        "      - 4 = Good: mostly correct sequence; handles common obstacles with minor inefficiencies; occasional unnecessary steps or suboptimal API usage.\n",
        "      - 3 = Mixed: reaches the goal or makes progress but with avoidable detours; slow or inconsistent adaptation to obstacles; noticeable inefficiencies (e.g., N+1 query patterns).\n",
        "      - 2 = Poor: often incorrect ordering of steps; weak adaptation; repeats failing actions; needs luck or external help to progress.\n",
        "      - 1 = Very poor: largely incoherent plan; frequently stuck; little to no useful adaptation; abandons after minor friction.\n",
        "      - 0 = Non-functional: no meaningful plan; stagnates immediately or repeatedly loops until the step budget is exhausted.\n",
        "    - planning_explanation: Brief justification for the planning score, including any efficiency issues.\n",
        "    \n",
        "    Then, evaluate reasoning quality:\n",
        "    - reasoning_score: Integer 0-5 for reasoning quality (correctness of inferences, use of context, sound logic)\n",
        "      Score scale:\n",
        "      - 5 = Excellent: all inferences correct and well-grounded; uses available context effectively; no logical errors; self-corrects when evidence contradicts assumptions.\n",
        "      - 4 = Good: mostly correct reasoning; minor inference gaps that don't derail the task; good use of context.\n",
        "      - 3 = Mixed: some correct reasoning but notable errors in logic or inference; may ignore relevant context or draw unsupported conclusions.\n",
        "      - 2 = Poor: frequent reasoning errors; draws conclusions not supported by evidence; misinterprets API responses or error messages.\n",
        "      - 1 = Very poor: pervasive logical flaws; assertions contradicted by available evidence; fails to connect cause and effect.\n",
        "      - 0 = Non-functional: reasoning is incoherent, contradictory, or absent; actions have no logical basis.\n",
        "    - reasoning_explanation: Brief justification for the reasoning score, noting any flawed inferences or logic errors.\n",
        "    \n",
        "    Then, evaluate API/tool handling:\n",
        "    - tool_use_score: Integer 0-5 for API/tool handling quality (endpoint selection, parameter formatting, error handling, response parsing)\n",
        "      Score scale:\n",
        "      - 5 = Excellent: selects correct endpoints consistently; parameters properly formatted with correct types/structure; handles errors gracefully; extracts and uses API response data accurately.\n",
        "      - 4 = Good: mostly correct endpoint/parameter usage; minor formatting issues that don't cause failures; reasonable error handling.\n",
        "      - 3 = Mixed: some incorrect endpoints or malformed parameters; may miss required fields or use wrong types; inconsistent error handling.\n",
        "      - 2 = Poor: frequent parameter errors (wrong names, types, structure); struggles to parse API responses; poor recovery from API errors.\n",
        "      - 1 = Very poor: pervasive API misuse; hallucinates endpoints or parameters; fails to extract needed data from responses.\n",
        "      - 0 = Non-functional: cannot successfully interact with APIs; all or most tool calls fail due to fundamental misuse.\n",
        "    - tool_use_explanation: Brief justification for the tool use score, noting any API misuse or parameter errors.\n",
        "    \n",
        "    Then, evaluate recovery ability:\n",
        "    - recovery_score: Integer 0-5 for recovery ability (failure detection, root cause diagnosis, applying corrective strategies)\n",
        "      Score scale:\n",
        "      - 5 = Excellent: quickly detects failures; accurately diagnoses root causes; applies effective corrective strategies (modifies params, switches tools, backtracks); learns from errors.\n",
        "      - 4 = Good: detects most failures; reasonable diagnosis; tries appropriate recovery strategies with minor delays or inefficiencies.\n",
        "      - 3 = Mixed: detects failures but slow to diagnose; may try ineffective strategies first; eventually finds working approach but wastes iterations.\n",
        "      - 2 = Poor: often misses or misinterprets failures; misdiagnoses root causes; applies wrong fixes; may retry same failing action multiple times.\n",
        "      - 1 = Very poor: rarely recognizes failures; no meaningful recovery attempts; gets stuck in loops or gives up immediately.\n",
        "      - 0 = Non-functional: completely unable to recover; ignores all error signals; repeats identical failures until timeout.\n",
        "    - recovery_explanation: Brief justification for the recovery score, noting recovery strategies used or missed opportunities.\n",
        "    \n",
        "    Then, evaluate hallucination resistance:\n",
        "    - hallucination_score: Integer 0-5 for hallucination resistance (5 = no hallucinations, 0 = severe hallucinations)\n",
        "      Score scale:\n",
        "      - 5 = None: no fabricated information; all claims grounded in trace, prompt, or API responses; no invented IDs, states, or outcomes.\n",
        "      - 4 = Minimal: one minor instance of ungrounded assertion that doesn't affect task outcome; quickly self-corrects if contradicted.\n",
        "      - 3 = Moderate: some fabricated details (e.g., guessed IDs, assumed states) but core reasoning remains sound; hallucinations don't derail task.\n",
        "      - 2 = Significant: multiple hallucinations affecting task execution; invents parameters, claims false successes, or fabricates API responses.\n",
        "      - 1 = Severe: pervasive fabrication; asserts non-existent capabilities, claims actions that didn't happen, or invents entire context.\n",
        "      - 0 = Extreme: nearly all assertions fabricated; completely disconnected from reality of trace; cannot distinguish real from invented.\n",
        "    - hallucination_explanation: Brief justification for the hallucination score, noting any fabricated information or false claims.\n",
        "    \n",
        "    Then provide narrative analysis:\n",
        "    - overall_description: 2-3 sentence summary of what went wrong and why, suitable for a paper's qualitative analysis section\n",
        "    - key_insight: The single most important takeaway from analyzing this run, specifically, what went well for RUN_TO_ANALYZE, what went wrong?\n",
        "    - model_behavior_pattern: What does this run reveal about how the model approaches this type of task?\n",
        "    - implications_for_reliability: What does this failure reveal about model reliability/robustness?\n",
        "    - worthy_example: Is this run interesting enough to feature in a qualitative analysis section of a paper? (true/false)\n",
        "    - why_worthy_example: If worthy, explain why this example is noteworthy. If not worthy, put 'N/A'.\n",
        "\n",
        "    Return your results in the required structured format.\"\"\"\n",
        "    \n",
        "    return SYSTEM_MSG, HUMAN_MSG_CUR_RUN, HUMAN_MSG_OTHER_RUN, RUN_ANALYSIS_PROMPT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fc881ca8"
      },
      "source": [
        "# Core functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "executionInfo": {
          "elapsed": 1899,
          "status": "ok",
          "timestamp": 1768563722228,
          "user": {
            "displayName": "Hubert Pyskło",
            "userId": "16424235253540376255"
          },
          "user_tz": -330
        },
        "id": "79b6c493"
      },
      "outputs": [],
      "source": [
        "def analyze_single_test(all_runs_for_test, langchain_model):\n",
        "    \"\"\"\n",
        "    Analyzes all runs for a single test_id.\n",
        "    \n",
        "    Args:\n",
        "        all_runs_for_test: All runs for this test (across all models) - used for finding best run\n",
        "                          and analyzing failed runs against it.\n",
        "        langchain_model: The LangChain model to use for analysis.\n",
        "    \n",
        "    Returns:\n",
        "        List of run analysis dicts, or None if all_runs_for_test is empty or has < 2 runs.\n",
        "    \"\"\"\n",
        "    if not all_runs_for_test:\n",
        "        print(\"WARNING: all_runs_for_test is empty. Returning.\")\n",
        "        return None\n",
        "    \n",
        "    # Check if we have at least 2 runs for comparison\n",
        "    if len(all_runs_for_test) < 2:\n",
        "        test_id = all_runs_for_test[0].get(\"runtime_test_id\", \"unknown\") if all_runs_for_test else \"unknown\"\n",
        "        print(f\"WARNING: Test {test_id} has only {len(all_runs_for_test)} run(s). Skipping comparison analysis (need at least 2 runs).\")\n",
        "        return None\n",
        "\n",
        "    # Sort best runs across ALL models for this test (highest score, fewest iterations)\n",
        "    sorted_runs = sorted(\n",
        "        all_runs_for_test,\n",
        "        key=lambda r: (r[\"score\"], -r.get(\"iterations\", float('inf'))),\n",
        "        reverse = True\n",
        "    )\n",
        "    \n",
        "    first_best_run = sorted_runs[0]\n",
        "    second_best_run = sorted_runs[1] if len(sorted_runs) > 1 else first_best_run\n",
        "    \n",
        "    i = 1\n",
        "    found_better = False\n",
        "    while i < len(sorted_runs):\n",
        "        if (sorted_runs[i][\"score\"] < first_best_run[\"score\"] or \n",
        "            sorted_runs[i][\"iterations\"] > first_best_run[\"iterations\"]):\n",
        "            break\n",
        "        \n",
        "        if (sorted_runs[i][\"include_api_docs\"] == True and\n",
        "            sorted_runs[i][\"include_all_api_docs\"] == False):\n",
        "            found_better = True\n",
        "            break\n",
        "\n",
        "        i += 1\n",
        "    \n",
        "    if found_better:   \n",
        "        second_best_run = first_best_run\n",
        "        first_best_run = sorted_runs[i]\n",
        "    \n",
        "    first_best_run_id = first_best_run[\"run_id\"]\n",
        "    \n",
        "    results = []\n",
        "\n",
        "    # Analyze each run (comprehensive assessment against best run)\n",
        "    for run in all_runs_for_test:\n",
        "        \n",
        "        # Choose another run for comparison\n",
        "        if run[\"run_id\"] == first_best_run_id:\n",
        "            other_run = second_best_run\n",
        "        else:\n",
        "            other_run = first_best_run\n",
        "        \n",
        "        other_run_trace = other_run.get(\"formatted_trace\", \"\")\n",
        "        other_run_score = other_run[\"score\"]\n",
        "        \n",
        "        cur_run_score = run[\"score\"]\n",
        "        \n",
        "        \n",
        "        if cur_run_score == 100:\n",
        "            other_run_type = \"ANOTHER_SUCCESSFUL_RUN\"\n",
        "        elif cur_run_score < 100 and other_run_score == 100:\n",
        "            other_run_type = \"BEST_RUN\"\n",
        "        elif cur_run_score < 100 and other_run_score < 100:\n",
        "            other_run_type = \"ONE_OF_THE_BEST_RUNS\"\n",
        "            \n",
        "        \n",
        "        \n",
        "        SYSTEM_MSG, HUMAN_MSG_CUR_RUN, HUMAN_MSG_OTHER_RUN, RUN_ANALYSIS_PROMPT = construct_run_analysis_prompt_elements(cur_run_score, other_run_type, other_run_score)        \n",
        "        \n",
        "\n",
        "        run_analysis = {\n",
        "            \"run_id\": run[\"run_id\"],\n",
        "            \"runtime_test_id\": run[\"runtime_test_id\"],\n",
        "            \"compared_against\": other_run[\"run_id\"]\n",
        "        }\n",
        "\n",
        "        try:\n",
        "            agent = create_agent(\n",
        "                model=langchain_model,\n",
        "                response_format=ToolStrategy(RunAnalysisSchema)\n",
        "            )\n",
        "\n",
        "            system_message = SYSTEM_MSG + RUN_ANALYSIS_PROMPT\n",
        "            human_message = HUMAN_MSG_CUR_RUN + run.get(\"formatted_trace\", \"\") + \"\\n\\n\" + HUMAN_MSG_OTHER_RUN + other_run.get(\"formatted_trace\", \"\")\n",
        "\n",
        "            result = agent.invoke({\n",
        "                \"messages\": [\n",
        "                    {\"role\": \"system\", \"content\": system_message},\n",
        "                    {\"role\": \"user\", \"content\": human_message}\n",
        "                ]\n",
        "            })\n",
        "\n",
        "            run_analysis[\"run_analysis\"] = result[\"structured_response\"]\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error analyzing run {run['run_id']}: {e}\")\n",
        "\n",
        "        results.append(run_analysis)\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "def group_runs_by_test(all_runs_formatted):\n",
        "    \"\"\"Group flat runs list by runtime_test_id.\"\"\"\n",
        "    from collections import defaultdict\n",
        "    grouped = defaultdict(list)\n",
        "    for run in all_runs_formatted:\n",
        "        grouped[run[\"runtime_test_id\"]].append(run)\n",
        "    return grouped\n",
        "\n",
        "\n",
        "def analyze_multiple_tests(langchain_model, all_runs_formatted=None, max_workers=10):\n",
        "    \"\"\"\n",
        "    Analyze all formatted runs, extracting qualitative data in structured format.\n",
        "    \n",
        "    Groups runs by test_id, then analyzes each test in parallel with checkpointing.\n",
        "    \n",
        "    Args:\n",
        "        langchain_model: The LangChain model to use for analysis.\n",
        "        all_runs_formatted: List of formatted runs (from format_single_run). \n",
        "                           If None, attempts to load from formatted_runs folder.\n",
        "        max_workers: Number of parallel workers for analysis.\n",
        "    \n",
        "    Returns:\n",
        "        List of run analysis dicts (flattened across all tests).\n",
        "    \"\"\"\n",
        "    \n",
        "    # Setup checkpoints folder\n",
        "    checkpoints_folder = os.path.join(os.getcwd(), \"checkpoints\")\n",
        "    os.makedirs(checkpoints_folder, exist_ok=True)\n",
        "    \n",
        "    # Create checkpoint file with timestamp\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    checkpoint_file = os.path.join(checkpoints_folder, f\"checkpoint_{timestamp}.json\")\n",
        "    print(f\"Using checkpoint file: {checkpoint_file}\")\n",
        "    \n",
        "    # Auto-load from formatted_runs folder if not provided\n",
        "    if not all_runs_formatted:\n",
        "        output_folder = os.path.join(os.getcwd(), \"formatted_runs\")\n",
        "        \n",
        "        if not os.path.exists(output_folder):\n",
        "            print(f\"ERROR: No runs provided and formatted_runs folder not found at {output_folder}\")\n",
        "            return []\n",
        "        \n",
        "        pattern = os.path.join(output_folder, \"all_runs_formatted_*.json\")\n",
        "        matching_files = sorted(glob.glob(pattern), reverse=True)  # newest first\n",
        "        \n",
        "        if not matching_files:\n",
        "            print(f\"ERROR: No all_runs_formatted_*.json files found in {output_folder}\")\n",
        "            return []\n",
        "        \n",
        "        latest_file = matching_files[0]\n",
        "        print(f\"Loading runs from: {latest_file}\")\n",
        "        \n",
        "        with open(latest_file, 'r') as f:\n",
        "            all_runs_formatted = json.load(f)\n",
        "        \n",
        "        print(f\"Loaded {len(all_runs_formatted)} formatted runs\")\n",
        "\n",
        "    results = []\n",
        "    processed_test_ids = set()\n",
        "\n",
        "    # Check for most recent existing checkpoint to resume from\n",
        "    existing_checkpoints = sorted(glob.glob(os.path.join(checkpoints_folder, \"checkpoint_*.json\")), reverse=True)\n",
        "    if existing_checkpoints:\n",
        "        latest_checkpoint = existing_checkpoints[0]\n",
        "        try:\n",
        "            with open(latest_checkpoint, 'r') as f:\n",
        "                results = json.load(f)\n",
        "                # Get processed test_ids from the flattened results\n",
        "                processed_test_ids = {r['runtime_test_id'] for r in results if r is not None}\n",
        "            print(f\"Resuming from checkpoint: {latest_checkpoint}\")\n",
        "            print(f\"Loaded {len(results)} already processed run analyses\")\n",
        "        except (json.JSONDecodeError, KeyError) as e:\n",
        "            print(f\"Could not load checkpoint {latest_checkpoint}: {e}. Starting fresh.\")\n",
        "\n",
        "    # Group runs by test_id\n",
        "    by_test = group_runs_by_test(all_runs_formatted)\n",
        "\n",
        "    # Filter to unprocessed tests\n",
        "    test_ids_to_process = [tid for tid in by_test.keys() if tid not in processed_test_ids]\n",
        "    print(f\"Processing {len(test_ids_to_process)} new tests (Total: {len(by_test)})\")\n",
        "\n",
        "    if not test_ids_to_process:\n",
        "        print(\"All tests already processed.\")\n",
        "        return results\n",
        "\n",
        "    # Process tests in parallel\n",
        "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
        "        future_to_test_id = {\n",
        "            executor.submit(analyze_single_test, by_test[tid], langchain_model): tid \n",
        "            for tid in test_ids_to_process\n",
        "        }\n",
        "        \n",
        "        for future in as_completed(future_to_test_id):\n",
        "            test_id = future_to_test_id[future]\n",
        "            try:\n",
        "                result = future.result()\n",
        "                if result is not None:\n",
        "                    results.extend(result)  # Flatten: extend instead of append\n",
        "                    print(f\"Completed analysis for test {test_id} ({len(result)} runs)\")\n",
        "                else:\n",
        "                    print(f\"Skipped test {test_id} (empty or insufficient runs)\")\n",
        "                \n",
        "                # Save checkpoint after each test\n",
        "                with open(checkpoint_file, 'w') as f:\n",
        "                    json.dump(results, f, indent=2)\n",
        "                    \n",
        "            except Exception as e:\n",
        "                print(f\"Error processing test {test_id}: {e}\")\n",
        "\n",
        "    # Save final results with timestamp\n",
        "    results_folder = os.path.join(os.getcwd(), \"qualitative_analysis_results\")\n",
        "    os.makedirs(results_folder, exist_ok=True)\n",
        "    \n",
        "    results_filepath = os.path.join(results_folder, f\"analysis_results_{timestamp}.json\")\n",
        "    \n",
        "    with open(results_filepath, 'w') as f:\n",
        "        json.dump(results, f, indent=2)\n",
        "    \n",
        "    print(f\"\\nSaved {len(results)} run analyses to: {results_filepath}\")\n",
        "    \n",
        "    return results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Run the analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define the model here using RobustChatOpenAI for retry logic\n",
        "\n",
        "# google/gemini-3-flash-preview\n",
        "# x-ai/grok-4.1-fast\n",
        "\n",
        "langchain_model = RobustChatOpenAI(\n",
        "    model=\"google/gemini-3-flash-preview\",\n",
        "    api_key=os.getenv(\"OPENROUTER_API_KEY\"),\n",
        "    base_url=\"https://openrouter.ai/api/v1\",\n",
        "    max_retries=3,\n",
        "    base_delay=2.0,\n",
        "    timeout=120,  # 120 second timeout for long-running requests\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "# selected_runs = [run for run in formatted_runs if run[\"runtime_test_id\"] == \"f1e306ca-d89a-5d70-bb57-03437eec4ea8\" or run[\"runtime_test_id\"] == \"0b2af335-8327-53fb-ab71-829299520d87\" or run[\"runtime_test_id\"] == \"10e491a0-bea6-5d05-9fb1-5d4774b34697\" or run[\"runtime_test_id\"] == \"2cae6822-7219-5357-b252-acd24e660f3b\"]\n",
        "\n",
        "# pprint(selected_runs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "7c6c3142755240ff9afff2e91442a445",
            "51c6409c22294fabbc01664d7c4a9a4b",
            "480f23463fcb4b43999a1188d5ef3138",
            "1cd3af2af88c44ca803e61975ad31e98",
            "eb2fed2af8744bcebe58cd6967679d98",
            "65b0c86c8543418191ae274e2048d33e",
            "f2486c53ea9b4ebeb8de2446aab1ff0f",
            "69cee69466274503a9657da66adeff45",
            "03dc844d5f5046e2bc79c6c7fbce7f73",
            "1b48f2ec1bd7409498d6c50766d3e8b3",
            "a6e16fe4fc0d4821bd4cde12c77fc6a3"
          ]
        },
        "executionInfo": {
          "elapsed": 580745,
          "status": "ok",
          "timestamp": 1768564304516,
          "user": {
            "displayName": "Hubert Pyskło",
            "userId": "16424235253540376255"
          },
          "user_tz": -330
        },
        "id": "ffc26f97",
        "outputId": "4a24b4c2-8732-478b-8a48-bec56fa7a468"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using checkpoint file: /Users/azh/agent-diff/local_analysis/checkpoints/checkpoint_20260208_163451.json\n",
            "Processing 223 new tests (Total: 223)\n",
            "Completed analysis for test 89b45222-2dee-535e-804e-69d1f44a78fd (18 runs)\n",
            "Completed analysis for test bf85c95d-b8ef-50cb-8263-6dae94173586 (18 runs)\n",
            "Completed analysis for test dcba769e-d40c-53c4-a6ae-11283f53ed77 (18 runs)\n",
            "Completed analysis for test b7b8f64c-6457-5f9c-8943-d4a9e83387f6 (18 runs)\n",
            "Completed analysis for test e4494bce-7101-5ec5-b757-f90f57c53690 (18 runs)\n",
            "Completed analysis for test 32ee4d07-7744-59c5-a91f-f9b6cb9b75b8 (18 runs)\n",
            "Completed analysis for test 2443b5cf-ef57-5201-9399-cba34df4649d (18 runs)\n",
            "Completed analysis for test 94e0cbdc-f816-57a6-a559-6578fd85f12c (18 runs)\n",
            "Completed analysis for test 316ccf74-4c28-5e2e-adf0-7b5037a5d236 (18 runs)\n",
            "Completed analysis for test f1e306ca-d89a-5d70-bb57-03437eec4ea8 (18 runs)\n",
            "Completed analysis for test 85cf6f38-d086-5590-bcea-45c7fd00b9ab (18 runs)\n",
            "Completed analysis for test 1a6f0dc0-3e38-5ca4-aa91-a179e553d56a (17 runs)\n",
            "Completed analysis for test 7585d11d-1522-5397-8f9d-4355c98fb320 (17 runs)\n",
            "Completed analysis for test 924b7358-0280-52a1-9f9d-ff92dc884408 (18 runs)\n",
            "Completed analysis for test 091c78d8-0a48-517f-ab2e-754a35ef6b41 (17 runs)\n",
            "Completed analysis for test 02afffa3-0d0f-563b-be3a-7b079f508960 (18 runs)\n",
            "Completed analysis for test 7e652804-c30e-5e96-b0a9-dacd4b301d3a (18 runs)\n",
            "Completed analysis for test 5b500d86-c978-51e9-926d-f0d692b970cc (18 runs)\n",
            "Completed analysis for test 306c1f11-1312-52ad-a8b9-345c8188d45b (18 runs)\n",
            "Completed analysis for test a55e938f-677f-55d7-b649-9635325c8497 (18 runs)\n",
            "Completed analysis for test 129d3b85-5f2d-5cf3-a47a-ca7132849fbd (18 runs)\n",
            "Completed analysis for test 109f7097-3c63-55a7-ad92-e0f5c728c27d (18 runs)\n",
            "Completed analysis for test c6f2e6f4-26a1-535e-9392-3b5efe077ec4 (18 runs)\n",
            "Completed analysis for test d779ff1b-b0ca-54ef-8ae3-258051b9019e (18 runs)\n",
            "Completed analysis for test 42a7f259-72c8-533c-80ba-5543663383b3 (17 runs)\n",
            "Completed analysis for test ff4b03db-720c-5073-acd1-96dcc23abb90 (18 runs)\n",
            "Completed analysis for test 8fa64981-967b-5085-836e-9df8ac4480d2 (17 runs)\n",
            "Completed analysis for test 9f4117c0-aeb5-5d9c-84ee-09bc82b928fe (18 runs)\n",
            "Completed analysis for test e713bdd8-45bc-5b53-a812-48431447b963 (18 runs)\n",
            "Completed analysis for test 96889276-121c-582f-a8d5-c6c5d4076b44 (18 runs)\n",
            "Completed analysis for test 36f37848-ec6e-5212-b940-f464f66988a1 (17 runs)\n",
            "Completed analysis for test 2b23b974-ce19-5cca-8f3a-501163a5035c (18 runs)\n",
            "Completed analysis for test b237178b-4673-5d49-ab33-537f6712c061 (18 runs)\n",
            "Completed analysis for test 0b1ba129-6828-587c-8279-523d12d2ce29 (18 runs)\n",
            "Completed analysis for test 35e70976-1895-5bda-a13d-c7131ba8815f (18 runs)\n",
            "Completed analysis for test 8f28c551-ac9a-5457-911f-7c313f4bfad0 (17 runs)\n",
            "Completed analysis for test e017c399-c0c1-5ebf-bb88-2308ac458819 (18 runs)\n",
            "Completed analysis for test 5720e37b-6000-599b-be8f-5e434744f01a (17 runs)\n",
            "Completed analysis for test 8850cf15-0881-5e2c-93f7-648b27e2ec82 (18 runs)\n",
            "Completed analysis for test 2726404a-0425-5911-838a-c09ab0aebd61 (18 runs)\n",
            "Completed analysis for test 0c52b193-a5ba-5ed1-81e0-eadf0fbf1eaa (18 runs)\n",
            "Completed analysis for test 4554cccc-efb0-591f-9d70-d475c28f3616 (18 runs)\n",
            "Completed analysis for test e7ba2b55-3d09-5124-b98c-b2f0f8e9e370 (18 runs)\n",
            "Completed analysis for test c217fe0e-a888-5059-b3d6-958372325e5d (18 runs)\n",
            "Completed analysis for test 6036938e-931f-5551-b3e2-8b505ef67d48 (18 runs)\n",
            "Completed analysis for test d1091560-faa4-5096-ae81-ce5e25439629 (18 runs)\n",
            "Completed analysis for test b50ec7a3-8627-5ed4-912a-0ba296b717e7 (18 runs)\n",
            "Completed analysis for test 87d92a6e-19c3-54d6-b9c4-1bfa9a781180 (18 runs)\n",
            "Completed analysis for test dd8580a5-0561-515a-a431-bb3c5d3bb01f (18 runs)\n",
            "Completed analysis for test cab8254e-a021-5cd7-a708-06fa208fe9c6 (18 runs)\n",
            "Completed analysis for test fc856770-93e4-5c53-ace1-bfc404682054 (18 runs)\n",
            "Completed analysis for test 8dfaba68-9f70-5276-886b-b7fa6fcc5dad (18 runs)\n",
            "Completed analysis for test 42079ca7-454f-5210-b8bc-a25a8d7e8b84 (18 runs)\n",
            "Completed analysis for test a50bb085-8db5-5d7e-ae62-31ab6ddd36f2 (18 runs)\n",
            "Completed analysis for test 22cc0553-80ea-5ed9-b7e6-49575d564465 (18 runs)\n",
            "Completed analysis for test 78e5fd8d-42cd-53ce-9dd9-50fb0deb7512 (18 runs)\n",
            "Completed analysis for test 6f073a5b-251a-55d5-bfc0-61c449e637c0 (18 runs)\n",
            "Completed analysis for test 8e87351f-f9ee-518a-ab07-5e48999e428c (18 runs)\n",
            "Completed analysis for test b9e23762-d395-50c4-b6a7-9f4d29e794d6 (18 runs)\n",
            "Completed analysis for test aaaaf30b-9078-52cd-8f7d-2ba22e4e78d7 (18 runs)\n",
            "Completed analysis for test 0214a404-85ed-5e1f-b17c-ce936aea6388 (18 runs)\n",
            "Completed analysis for test 2b53f5da-6341-5faf-82f9-7a33b0026836 (18 runs)\n",
            "Completed analysis for test 57f88692-caaa-5686-bbee-693882f00d30 (18 runs)\n",
            "Completed analysis for test 0873de14-fa61-5f82-9915-4cb49e5e9ba6 (18 runs)\n",
            "Completed analysis for test b9372abf-df90-5abd-a439-5636a10c944c (18 runs)\n",
            "Completed analysis for test 78351c1c-adc1-51d7-a9ae-97bf4d8fec5a (18 runs)\n",
            "Completed analysis for test b54edc1f-8946-5aa7-98bc-63ff8f048799 (18 runs)\n",
            "Completed analysis for test e2769ac6-9466-5a53-bbd3-5fa2be79f9a5 (18 runs)\n",
            "Completed analysis for test 57da6e5c-ac68-5422-b6fc-2d6d56de8f55 (18 runs)\n",
            "Completed analysis for test 521e343d-de96-5c51-afac-23a2d63c0ade (18 runs)\n",
            "Completed analysis for test 140123d2-1f83-59a4-8e09-8d1135930d05 (18 runs)\n",
            "Completed analysis for test f0f327f4-3e41-5c78-88e6-623a5954e31d (18 runs)\n",
            "Completed analysis for test 16b83c1b-8b86-5d35-93d3-e49810c14396 (18 runs)\n",
            "Completed analysis for test 99c8efa3-c260-574b-bbde-3280e07c4beb (18 runs)\n",
            "Completed analysis for test 1e9b13ae-6e8f-5874-865a-fc0304bc54e0 (18 runs)\n",
            "Completed analysis for test da7c1952-ef34-54dc-a0b6-6ef3f9fb2ad2 (18 runs)\n",
            "Completed analysis for test 64812e17-adfc-53b9-a92d-1382e851afe9 (18 runs)\n",
            "Completed analysis for test 981a1276-8cb0-5569-a3a0-e3796cfff1bc (18 runs)\n",
            "Completed analysis for test 9a2694eb-92f3-5b68-9918-4b492b57ee55 (18 runs)\n",
            "Completed analysis for test ad8adea9-1a0e-51fc-9e96-c7da2349f061 (16 runs)\n",
            "Completed analysis for test 609ed1c6-a5af-528a-9a00-380c400f2511 (18 runs)\n",
            "Completed analysis for test 570b8931-e0ae-5e4a-b1a4-e03847e220d6 (18 runs)\n",
            "Completed analysis for test 705152cc-e799-536c-9eaf-7b03e73e4cd8 (18 runs)\n",
            "Completed analysis for test 0dfb2d4f-8bd1-5790-bc27-74b27d3650c0 (18 runs)\n",
            "Completed analysis for test ffaeced3-a011-5f58-a036-54f3135dd3f1 (17 runs)\n",
            "Completed analysis for test dc01a0ee-f4df-5df1-8b1d-b1a36b2a275b (18 runs)\n",
            "Completed analysis for test 675c62bb-af91-5311-a606-d46c53bf2d20 (18 runs)\n",
            "Completed analysis for test bfb139ab-2eaf-565b-83ef-f5c7d849ca78 (18 runs)\n",
            "Completed analysis for test 3e0e5027-1788-5063-9dab-f5bb31253cd5 (17 runs)\n",
            "Completed analysis for test afbcedcd-c76a-55a6-a978-9aca0849ff0e (18 runs)\n",
            "Completed analysis for test 63ef0d2c-0d08-5a1c-876f-3d534b58c60d (18 runs)\n",
            "Completed analysis for test 958ef51f-18f0-5419-a911-7ab6977e846b (18 runs)\n",
            "Completed analysis for test 51e9be5b-2f83-5619-a210-44bd1f431390 (18 runs)\n",
            "Completed analysis for test af79a4d9-e765-54ce-af39-e55c3951d88c (18 runs)\n",
            "Completed analysis for test 8dc4713a-24ab-5d6f-bf7c-1d61104c7e0a (18 runs)\n",
            "Completed analysis for test 7966afdf-9278-52f7-8343-c101d5cf69ac (18 runs)\n",
            "Completed analysis for test a8cc67b2-4791-590d-9379-a6b57bb17a4a (18 runs)\n",
            "Completed analysis for test 2b18b922-58fe-5a37-b155-a113e8a4407b (18 runs)\n",
            "Completed analysis for test 0b2af335-8327-53fb-ab71-829299520d87 (18 runs)\n",
            "Completed analysis for test 4c89f90d-83e0-523d-972f-5cd4b2e88d97 (18 runs)\n",
            "Completed analysis for test 1a82a12f-8ffa-5475-8b52-1dae7749d54b (18 runs)\n",
            "Completed analysis for test 9e5d8660-1923-5951-8931-5da5079dabcb (18 runs)\n",
            "Completed analysis for test 3ff36a75-226b-568c-8bca-811dabdf407f (18 runs)\n",
            "Completed analysis for test 2cae6822-7219-5357-b252-acd24e660f3b (18 runs)\n",
            "Completed analysis for test 12cb6906-07b3-5bab-8097-2bd87ba82e89 (18 runs)\n",
            "Completed analysis for test b06a3dd5-bcb0-55c8-a581-9c9a8363efbe (18 runs)\n",
            "Completed analysis for test 10e491a0-bea6-5d05-9fb1-5d4774b34697 (18 runs)\n",
            "Completed analysis for test c3370974-2e42-5a98-858f-1a4857cee7e5 (18 runs)\n",
            "Completed analysis for test b2990fe2-32f8-518d-b071-9bdb8c1695c1 (18 runs)\n",
            "Completed analysis for test 30cc2076-4024-58d0-b109-0a47fff41303 (18 runs)\n",
            "Completed analysis for test d8fa727a-0083-5d34-b56d-8f0483106b8b (18 runs)\n",
            "Completed analysis for test e8f8a489-55ac-5593-b899-105cb9d87aad (18 runs)\n",
            "Completed analysis for test 7d35e11a-12e9-598e-9cdf-6a15c81c034f (17 runs)\n",
            "Completed analysis for test a2a08945-3a17-5534-804f-115b47cb2aee (18 runs)\n",
            "Completed analysis for test cfcdc9df-af26-5dd1-b6c8-d3b1dab9ec96 (18 runs)\n",
            "Completed analysis for test fe997459-1ea7-594b-8f33-c2acc1754378 (18 runs)\n",
            "Completed analysis for test e45c8a94-d19d-576d-91f7-aae559918dd0 (18 runs)\n",
            "Completed analysis for test 7d481aeb-e1ec-557f-a349-d5281633af58 (18 runs)\n",
            "Completed analysis for test 9ccbf958-0d88-5cc0-99eb-ccc7ffd62d5f (18 runs)\n",
            "Completed analysis for test fd9ca02d-daca-530a-bed5-66c4ee9be71f (18 runs)\n",
            "Completed analysis for test b9f5bfa5-293c-5ac2-a4c6-43cdb9f21c71 (18 runs)\n",
            "Completed analysis for test ad4fe3b0-d667-5b40-a1ca-68a056662239 (18 runs)\n",
            "Completed analysis for test 1ef0a1d7-230c-5d07-88a7-25b3a13efac9 (18 runs)\n",
            "Completed analysis for test defec824-662c-5591-8fe6-573eb6e82441 (18 runs)\n",
            "Completed analysis for test e3ff34bf-14e8-51aa-9972-f9c1622f6ae4 (18 runs)\n",
            "Completed analysis for test e014f04a-eb13-5836-8ddb-eb8d9d7331d0 (18 runs)\n",
            "Completed analysis for test 0a60ffaa-7d1b-54d5-89c8-aff960776a19 (18 runs)\n",
            "Completed analysis for test ea627ab4-f0c7-5c16-b986-b970c11cbc93 (18 runs)\n",
            "Completed analysis for test f195c71d-4e5f-55a8-aa31-e771eed5be92 (18 runs)\n",
            "Completed analysis for test 2059ef1a-ec6e-54b3-8038-afd69c5fe876 (18 runs)\n",
            "Completed analysis for test f2cf962c-6253-592d-b205-1da7ef72b674 (18 runs)\n",
            "Completed analysis for test 0e363f34-4cd1-5fb8-8d37-fdf88cfbf855 (18 runs)\n",
            "Completed analysis for test 62f58346-ef22-52f3-86fe-5f4140a5d491 (18 runs)\n",
            "Completed analysis for test 58c2ac95-b0a5-5630-af0b-78c973c3831a (18 runs)\n",
            "Completed analysis for test 1aaa6dfc-87dc-51db-ac76-506642928cbf (18 runs)\n",
            "Completed analysis for test bcf8296c-2507-527b-bb27-16319a962c68 (18 runs)\n",
            "Completed analysis for test 143f7c38-8c3d-5778-8daf-5d57fc7f1727 (18 runs)\n",
            "Completed analysis for test 3fee3b45-d12f-5ef2-a675-8ee153f1aa19 (18 runs)\n",
            "Completed analysis for test 1ed6d367-32d3-5e70-b4fb-ab483f61ccc0 (18 runs)\n",
            "Completed analysis for test 31f504c0-a935-54b4-88d9-519f99bc644d (18 runs)\n",
            "Completed analysis for test cf96de3e-12e5-50d9-86f2-f32042a5c834 (18 runs)\n",
            "Completed analysis for test 3c878e45-54e8-5c41-af55-c3e4cec239e0 (18 runs)\n",
            "Completed analysis for test 812e328a-9e48-506d-8680-566b32da56b6 (18 runs)\n",
            "Completed analysis for test 4044d868-4f9f-53dd-9213-6c4653a6bdcc (18 runs)\n",
            "Completed analysis for test 36624405-625b-52c6-8430-e9bb7b6a1a25 (18 runs)\n",
            "Completed analysis for test a462ebc5-65ef-5f0f-92f0-6e19387eeab5 (18 runs)\n",
            "Completed analysis for test 8ad0cf81-2911-5b5a-a706-4c196892c3b8 (18 runs)\n",
            "Completed analysis for test cdd3cbfc-6e86-59c3-97ac-ce2ef3999b3d (18 runs)\n",
            "Completed analysis for test 7967f654-844e-5e1f-b099-084ca562a403 (17 runs)\n",
            "Completed analysis for test cf193231-8fc6-5f0c-8503-6cbb9454a3cc (17 runs)\n",
            "Completed analysis for test 42ec30d7-1fda-5512-b335-8c3c50b4b6d4 (17 runs)\n",
            "Completed analysis for test f80074a5-8690-5963-aa4a-99637b06d5b3 (18 runs)\n",
            "Completed analysis for test e39e236d-c1e3-565f-87d2-2673f8471eee (18 runs)\n",
            "Completed analysis for test 004e078a-0cb4-5a33-ae7d-4d1e44131c1f (18 runs)\n",
            "Completed analysis for test 26becca0-cd02-5e0c-8ec7-6bddc2b8a7ae (18 runs)\n",
            "Completed analysis for test 2f0a86aa-ae09-5894-b849-b2eef4c8ebbc (18 runs)\n",
            "Completed analysis for test c65656a6-58ac-5507-b606-5c8e329137f3 (18 runs)\n",
            "Completed analysis for test 3ab4da80-59fc-5224-b8aa-dc733b483c6e (18 runs)\n",
            "Completed analysis for test 8ee5f307-667b-5148-a530-6fc1990a6e47 (18 runs)\n",
            "Completed analysis for test 9437a1f2-7796-5f55-b020-7e2835a0a601 (17 runs)\n",
            "Completed analysis for test 1bff659b-ec87-56f4-aeef-ca95765a1281 (18 runs)\n",
            "Completed analysis for test c123d805-a4b3-589f-b7be-f57c0030e9a0 (18 runs)\n",
            "Completed analysis for test 41f6d424-fd8e-50f1-9473-695453d474d3 (18 runs)\n",
            "Completed analysis for test db4e374b-86d2-5e8b-956c-018a8713c727 (17 runs)\n",
            "Completed analysis for test 71535acb-d295-5086-84a2-1b71a9b770b0 (18 runs)\n",
            "Completed analysis for test 497cf619-7f19-5a7b-9f4e-8d0638a80479 (18 runs)\n",
            "Completed analysis for test eeedc7d1-7a4d-5bfc-84ee-36ba982206de (18 runs)\n",
            "Completed analysis for test 00d56d81-e3db-5c48-a650-f8b602a3158c (18 runs)\n",
            "Completed analysis for test 2f83b766-7760-52c6-a5ef-a0d3a82ca83f (18 runs)\n",
            "Completed analysis for test 363cadc2-4530-54f7-9bd1-c80e036752fe (18 runs)\n",
            "Completed analysis for test 0c33ae93-3188-562e-880f-e9858837b7ac (17 runs)\n",
            "Completed analysis for test c89e10e6-df2f-5f3c-99a5-94614b95e86d (18 runs)\n",
            "Completed analysis for test 51f7e2ed-552e-5889-8751-77e0ee578060 (18 runs)\n",
            "Completed analysis for test aa973966-9a27-52e8-9e92-a72c0a1c9689 (17 runs)\n",
            "Completed analysis for test 98194ce2-41ce-5c68-b541-1f1ddc14a971 (17 runs)\n",
            "Completed analysis for test d5d92862-3032-5454-87a0-68ed0864682c (16 runs)\n",
            "Completed analysis for test 7aac1181-effd-56d8-b2a6-dffe40194ec9 (18 runs)\n",
            "Completed analysis for test 6fc46b3c-2753-5d3d-902a-1d977a4fe10b (18 runs)\n",
            "Completed analysis for test c256f46d-6219-5be2-a557-fed458f7dea4 (18 runs)\n",
            "Completed analysis for test ff35db06-0241-5e60-b000-7101a4c7db1e (18 runs)\n",
            "Completed analysis for test 8d963004-d82f-5118-a56c-614f313461d2 (18 runs)\n",
            "Completed analysis for test eb537845-3ab6-5394-997e-93c8298a38cc (16 runs)\n",
            "Completed analysis for test d7f76199-917c-5543-9477-dd49ac921492 (18 runs)\n",
            "Completed analysis for test c681601c-1b00-5614-a53f-e5899da6ceec (18 runs)\n",
            "Completed analysis for test 8e5863ba-7970-5cec-b43c-cd67add71e49 (18 runs)\n",
            "Completed analysis for test a476bbc1-4a60-5542-9f28-56dd8aacf677 (18 runs)\n",
            "Completed analysis for test 73950712-e215-5c6c-b494-b8bc3564a767 (18 runs)\n",
            "Completed analysis for test 34284b81-7802-5cdd-a975-88a4d33d640c (18 runs)\n",
            "Completed analysis for test a4025b7e-d998-5701-891e-a0181bc07168 (18 runs)\n",
            "Completed analysis for test 49c2d126-9979-5a21-a008-2594051a1b93 (18 runs)\n",
            "Completed analysis for test 158a173e-168b-54cf-af59-93e523b5c6e8 (18 runs)\n",
            "Completed analysis for test 0f49728f-5f8b-5a3a-babc-b81026fce1fd (16 runs)\n",
            "Completed analysis for test 7a911ab0-27fb-5345-9529-afdfb92d7f74 (18 runs)\n",
            "Completed analysis for test ea937609-6906-5602-ad0b-4cedfb69dfe6 (18 runs)\n",
            "Completed analysis for test 220eaa92-b1bc-5064-90b4-40e6062ff73b (17 runs)\n",
            "Completed analysis for test 7bb93bc7-c3a2-5dc1-b387-2f7f1b53eb42 (18 runs)\n",
            "Completed analysis for test 209c8362-8457-5bff-96a0-dbfe5f1a9f8b (16 runs)\n",
            "Completed analysis for test 5892c247-dc0b-5b3e-a2cd-bd07c2dcbc60 (16 runs)\n",
            "Completed analysis for test 38e6a618-996f-549c-b397-05de6c6081aa (18 runs)\n",
            "Completed analysis for test 117b210a-623b-5626-b5b9-199835bda5e3 (18 runs)\n",
            "Completed analysis for test af828a7f-4856-5d75-a0b7-03912092505d (17 runs)\n",
            "Completed analysis for test ce6072c1-1582-5822-a930-c8faeed8fe1a (18 runs)\n",
            "Completed analysis for test f031b96e-5144-5c3f-85e9-b79795244d0f (18 runs)\n",
            "Completed analysis for test 959b0734-eb18-51ec-a704-dfe79a025917 (16 runs)\n",
            "Completed analysis for test a3bc97ee-a7fb-595a-8e96-9e900837a1ca (17 runs)\n",
            "Completed analysis for test 860399a5-508e-5389-a662-24420a49986b (18 runs)\n",
            "Completed analysis for test f425dc39-43db-562a-9ef7-9d8aecf3c3bf (17 runs)\n",
            "Completed analysis for test ed430ef0-1f5f-5fd2-98e4-b9042d714cfc (18 runs)\n",
            "Completed analysis for test c0319f84-59ce-516f-be97-70f2fa3b1db0 (18 runs)\n",
            "Completed analysis for test 08f51926-10ba-5e9c-bfde-805c9bc30466 (18 runs)\n",
            "Completed analysis for test 5fbfccd0-5281-5cc9-b5ae-851ec0a3484a (16 runs)\n",
            "Completed analysis for test ac1ef9e0-f096-50ba-a002-377dac2e0abd (18 runs)\n",
            "Completed analysis for test 4e2c2e3c-8e5f-584b-ae9b-95a14f329b85 (18 runs)\n",
            "Completed analysis for test 7e9df9f5-3111-5ba1-b86c-094bbd30a77d (18 runs)\n",
            "Completed analysis for test d979f152-4b6a-57b8-ac51-f2702776e7c9 (17 runs)\n",
            "Completed analysis for test 8b68c888-f8b4-51d7-8c7b-bfb2951c8a10 (18 runs)\n",
            "Completed analysis for test 58bf5ab4-7e3b-58d2-aa78-7234452fc990 (18 runs)\n",
            "Completed analysis for test f244681f-ca80-52a2-baf1-d357eca72075 (18 runs)\n",
            "Completed analysis for test 6fa21b40-f1ee-579e-a122-7f97e6a22d8f (18 runs)\n",
            "Completed analysis for test 7999d609-cda4-5b74-bb8f-18a434525f9f (8 runs)\n",
            "Completed analysis for test ed335427-ce65-543c-b258-e506fc560b36 (18 runs)\n",
            "Completed analysis for test 0e2f777e-34b8-52ec-9fb0-a73c44d1cad5 (18 runs)\n",
            "Completed analysis for test d8d847f2-900d-50a9-b535-e21b97c89be5 (17 runs)\n",
            "\n",
            "Saved 3963 run analyses to: /Users/azh/agent-diff/local_analysis/qualitative_analysis_results/analysis_results_20260208_163451.json\n"
          ]
        }
      ],
      "source": [
        "analysis_results = analyze_multiple_tests(langchain_model=langchain_model,\n",
        "                                          all_runs_formatted=formatted_runs, # By default (if None is specified) will process last file with formatted runs\n",
        "                                          max_workers=10)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "03dc844d5f5046e2bc79c6c7fbce7f73": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1b48f2ec1bd7409498d6c50766d3e8b3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1cd3af2af88c44ca803e61975ad31e98": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1b48f2ec1bd7409498d6c50766d3e8b3",
            "placeholder": "​",
            "style": "IPY_MODEL_a6e16fe4fc0d4821bd4cde12c77fc6a3",
            "value": " 609/609 [09:40&lt;00:00,  5.21s/it]"
          }
        },
        "480f23463fcb4b43999a1188d5ef3138": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_69cee69466274503a9657da66adeff45",
            "max": 609,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_03dc844d5f5046e2bc79c6c7fbce7f73",
            "value": 609
          }
        },
        "51c6409c22294fabbc01664d7c4a9a4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_65b0c86c8543418191ae274e2048d33e",
            "placeholder": "​",
            "style": "IPY_MODEL_f2486c53ea9b4ebeb8de2446aab1ff0f",
            "value": "Analyzing Traces: 100%"
          }
        },
        "65b0c86c8543418191ae274e2048d33e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69cee69466274503a9657da66adeff45": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c6c3142755240ff9afff2e91442a445": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_51c6409c22294fabbc01664d7c4a9a4b",
              "IPY_MODEL_480f23463fcb4b43999a1188d5ef3138",
              "IPY_MODEL_1cd3af2af88c44ca803e61975ad31e98"
            ],
            "layout": "IPY_MODEL_eb2fed2af8744bcebe58cd6967679d98"
          }
        },
        "a6e16fe4fc0d4821bd4cde12c77fc6a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eb2fed2af8744bcebe58cd6967679d98": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2486c53ea9b4ebeb8de2446aab1ff0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
